<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of ml_trainsvmlight</title>
  <meta name="keywords" content="ml_trainsvmlight">
  <meta name="description" content="Learn a linear or non-linear predictive model by Support Vector Machines, using SVMlight.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../index.html">Home</a> &gt;  <a href="#">code</a> &gt; <a href="index.html">machine_learning</a> &gt; ml_trainsvmlight.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../index.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for code/machine_learning&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>ml_trainsvmlight
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>Learn a linear or non-linear predictive model by Support Vector Machines, using SVMlight.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function model = ml_trainsvmlight(varargin) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Learn a linear or non-linear predictive model by Support Vector Machines, using SVMlight.
 Model = ml_trainsvmlight(Trials, Targets, Cost, Options...)

 SVMlight [1] is a comprehensive and fast implementation of Support Vector Machines [2] that
 supports, in addition to classification, also regression and ranking; it further offers a variety
 of kernels for state-of-the-art non-linear prediction. An alternative implementation which offers
 a greater variety of loss measures for classification is SVMperf (see ml_trainsvmperf). For
 further details, see ml_trainsvmperf.

 For non-linear ranking problems, this is the online applicable method in the toolbox, for
 non-linear regression problems, the only alternative is the Relevance Vector Machine, and for
 (arbitrary) non-linear classification problems, the alternatives is the Relevance Vector Machine
 and SVMperf.

 In:
   Trials   : training data, as in ml_train

   Targets  : target variable, as in ml_train

   Cost     : regularization parameter, reasonable range: 2.^(-5:2:15), greater is stronger

   Options  : optional name-value parameters to control the training details, see below in code for full help
               'ptype': problem type: 'classification' (default), 'regression', and 'ranking'
               'tube': epsilon width of tube for regression (default 0.1)
               'balance': positive weight / negative weight
              kernel parameters:
               'kernel': ptype of kernel function (linear,poly,rbf,sigmoid,user); (default: 'rbf')
               'gamma': parameter gamma in rbf kernel; reasonable search range: 2.^(-16:2:4) (default: 0.3)
               'd': parameter d in polynomial kernel (default: 3)
               's': parameter s in sigmoid/poly kernel (default: 1)
               'r': parameter c in sigmoid/poly kernel (default: 1)
               'u': parameter of user-defined kernel (default: '1')
              misc options:
               'eps': tolerance (e.g., 0.1)
               'bias': bias present? (0,1)
               'clean': clean inconsistent data before start? (0,1)
               'verbose': verbosity level (0,1)
               'scaling': pre-scaling, see hlp_findscaling (default: 'std')

 Out:
   Model   : a linear model; 
             classes indicates the class labels which the model predicts
             sc_info is the scaling info

 Examples:
   % learn a quick and dirty SVM model (without parameter search)
   model = ml_trainsvmlight(trials,labels)

   % as before, but this time learn a regression model
   model = ml_trainsvm(trials,labels,1,'ptype','regression')

   % learn an SVM model by searching over the cost parameter (note: quite slow)
   model = utl_searchmodel({trials,labels},'args',{{'svmlight',search(2.^(-5:2:15))}})

   % as before, but also search over the kernel scale parameter (note: really slow)
   model = utl_searchmodel({trials,labels},'args',{{'svmlight',search(2.^(-5:2:15)),'gamma',search(2.^(-16:2:4))}})

   % as before, but use a linear kernel (no need to search over gamma, then)
   model = utl_searchmodel({trials,labels},'args',{{'svmlight',search(2.^(-5:2:15)),'kernel','linear'}})

   % as before, but learn a ranking model
   model = utl_searchmodel({trials,labels},'args',{{'svmlight',search(2.^(-5:2:15)),'kernel','linear','ptype','ranking'}})
   
 See also:
   <a href="ml_predictsvmlight.html" class="code" title="function pred = ml_predictsvmlight(trials, model)">ml_predictsvmlight</a>, svmlearn

 References:
   [1] Thorsten Joachims, &quot;Learning to Classify Text Using Support Vector Machines&quot;
       Dissertation, Kluwer, 2002.
   [2] Schoelkopf, B., and Smola, A. &quot;Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond&quot;
       (Adaptive Computation and Machine Learning). The MIT Press, Dec. 2001.

                           Christian Kothe, Swartz Center for Computational Neuroscience, UCSD
                           2010-04-04</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="ml_predictsvmlight.html" class="code" title="function pred = ml_predictsvmlight(trials, model)">ml_predictsvmlight</a>	Prediction function for the Support Vector Machine (SVMlight).</li><li><a href="ml_trainsvmlight.html" class="code" title="function model = ml_trainsvmlight(varargin)">ml_trainsvmlight</a>	Learn a linear or non-linear predictive model by Support Vector Machines, using SVMlight.</li><li><a href="ml_trainvote.html" class="code" title="function model = ml_trainvote(trials, targets, votingscheme, learner, predictor, varargin)">ml_trainvote</a>	Internal meta-algorithm for voting. Used by other machine learning functions.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="ml_trainsvmlight.html" class="code" title="function model = ml_trainsvmlight(varargin)">ml_trainsvmlight</a>	Learn a linear or non-linear predictive model by Support Vector Machines, using SVMlight.</li></ul>
<!-- crossreference -->



<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function model = ml_trainsvmlight(varargin)</a>
0002 <span class="comment">% Learn a linear or non-linear predictive model by Support Vector Machines, using SVMlight.</span>
0003 <span class="comment">% Model = ml_trainsvmlight(Trials, Targets, Cost, Options...)</span>
0004 <span class="comment">%</span>
0005 <span class="comment">% SVMlight [1] is a comprehensive and fast implementation of Support Vector Machines [2] that</span>
0006 <span class="comment">% supports, in addition to classification, also regression and ranking; it further offers a variety</span>
0007 <span class="comment">% of kernels for state-of-the-art non-linear prediction. An alternative implementation which offers</span>
0008 <span class="comment">% a greater variety of loss measures for classification is SVMperf (see ml_trainsvmperf). For</span>
0009 <span class="comment">% further details, see ml_trainsvmperf.</span>
0010 <span class="comment">%</span>
0011 <span class="comment">% For non-linear ranking problems, this is the online applicable method in the toolbox, for</span>
0012 <span class="comment">% non-linear regression problems, the only alternative is the Relevance Vector Machine, and for</span>
0013 <span class="comment">% (arbitrary) non-linear classification problems, the alternatives is the Relevance Vector Machine</span>
0014 <span class="comment">% and SVMperf.</span>
0015 <span class="comment">%</span>
0016 <span class="comment">% In:</span>
0017 <span class="comment">%   Trials   : training data, as in ml_train</span>
0018 <span class="comment">%</span>
0019 <span class="comment">%   Targets  : target variable, as in ml_train</span>
0020 <span class="comment">%</span>
0021 <span class="comment">%   Cost     : regularization parameter, reasonable range: 2.^(-5:2:15), greater is stronger</span>
0022 <span class="comment">%</span>
0023 <span class="comment">%   Options  : optional name-value parameters to control the training details, see below in code for full help</span>
0024 <span class="comment">%               'ptype': problem type: 'classification' (default), 'regression', and 'ranking'</span>
0025 <span class="comment">%               'tube': epsilon width of tube for regression (default 0.1)</span>
0026 <span class="comment">%               'balance': positive weight / negative weight</span>
0027 <span class="comment">%              kernel parameters:</span>
0028 <span class="comment">%               'kernel': ptype of kernel function (linear,poly,rbf,sigmoid,user); (default: 'rbf')</span>
0029 <span class="comment">%               'gamma': parameter gamma in rbf kernel; reasonable search range: 2.^(-16:2:4) (default: 0.3)</span>
0030 <span class="comment">%               'd': parameter d in polynomial kernel (default: 3)</span>
0031 <span class="comment">%               's': parameter s in sigmoid/poly kernel (default: 1)</span>
0032 <span class="comment">%               'r': parameter c in sigmoid/poly kernel (default: 1)</span>
0033 <span class="comment">%               'u': parameter of user-defined kernel (default: '1')</span>
0034 <span class="comment">%              misc options:</span>
0035 <span class="comment">%               'eps': tolerance (e.g., 0.1)</span>
0036 <span class="comment">%               'bias': bias present? (0,1)</span>
0037 <span class="comment">%               'clean': clean inconsistent data before start? (0,1)</span>
0038 <span class="comment">%               'verbose': verbosity level (0,1)</span>
0039 <span class="comment">%               'scaling': pre-scaling, see hlp_findscaling (default: 'std')</span>
0040 <span class="comment">%</span>
0041 <span class="comment">% Out:</span>
0042 <span class="comment">%   Model   : a linear model;</span>
0043 <span class="comment">%             classes indicates the class labels which the model predicts</span>
0044 <span class="comment">%             sc_info is the scaling info</span>
0045 <span class="comment">%</span>
0046 <span class="comment">% Examples:</span>
0047 <span class="comment">%   % learn a quick and dirty SVM model (without parameter search)</span>
0048 <span class="comment">%   model = ml_trainsvmlight(trials,labels)</span>
0049 <span class="comment">%</span>
0050 <span class="comment">%   % as before, but this time learn a regression model</span>
0051 <span class="comment">%   model = ml_trainsvm(trials,labels,1,'ptype','regression')</span>
0052 <span class="comment">%</span>
0053 <span class="comment">%   % learn an SVM model by searching over the cost parameter (note: quite slow)</span>
0054 <span class="comment">%   model = utl_searchmodel({trials,labels},'args',{{'svmlight',search(2.^(-5:2:15))}})</span>
0055 <span class="comment">%</span>
0056 <span class="comment">%   % as before, but also search over the kernel scale parameter (note: really slow)</span>
0057 <span class="comment">%   model = utl_searchmodel({trials,labels},'args',{{'svmlight',search(2.^(-5:2:15)),'gamma',search(2.^(-16:2:4))}})</span>
0058 <span class="comment">%</span>
0059 <span class="comment">%   % as before, but use a linear kernel (no need to search over gamma, then)</span>
0060 <span class="comment">%   model = utl_searchmodel({trials,labels},'args',{{'svmlight',search(2.^(-5:2:15)),'kernel','linear'}})</span>
0061 <span class="comment">%</span>
0062 <span class="comment">%   % as before, but learn a ranking model</span>
0063 <span class="comment">%   model = utl_searchmodel({trials,labels},'args',{{'svmlight',search(2.^(-5:2:15)),'kernel','linear','ptype','ranking'}})</span>
0064 <span class="comment">%</span>
0065 <span class="comment">% See also:</span>
0066 <span class="comment">%   ml_predictsvmlight, svmlearn</span>
0067 <span class="comment">%</span>
0068 <span class="comment">% References:</span>
0069 <span class="comment">%   [1] Thorsten Joachims, &quot;Learning to Classify Text Using Support Vector Machines&quot;</span>
0070 <span class="comment">%       Dissertation, Kluwer, 2002.</span>
0071 <span class="comment">%   [2] Schoelkopf, B., and Smola, A. &quot;Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond&quot;</span>
0072 <span class="comment">%       (Adaptive Computation and Machine Learning). The MIT Press, Dec. 2001.</span>
0073 <span class="comment">%</span>
0074 <span class="comment">%                           Christian Kothe, Swartz Center for Computational Neuroscience, UCSD</span>
0075 <span class="comment">%                           2010-04-04</span>
0076 
0077 arg_define([0 3],varargin, <span class="keyword">...</span>
0078     arg_norep(<span class="string">'trials'</span>), <span class="keyword">...</span>
0079     arg_norep(<span class="string">'targets'</span>), <span class="keyword">...</span>
0080     arg({<span class="string">'cost'</span>,<span class="string">'Cost'</span>}, search(2.^(-5:2:15)), [], <span class="string">'Regularization parameter. Reasonable range: 2.^(-5:2:15), greater is stronger. By default, it is average(x*x) ^ -1.'</span>,<span class="string">'cat'</span>,<span class="string">'Core Parameters'</span>), <span class="keyword">...</span>
0081     arg({<span class="string">'ptype'</span>,<span class="string">'Type'</span>}, <span class="string">'classification'</span>, {<span class="string">'classification'</span>,<span class="string">'regression'</span>,<span class="string">'ranking'</span>}, <span class="string">'Type of problem to solve.'</span>,<span class="string">'cat'</span>,<span class="string">'Core Parameters'</span>), <span class="keyword">...</span>
0082     arg({<span class="string">'kernel'</span>,<span class="string">'Kernel'</span>}, <span class="string">'rbf'</span>, {<span class="string">'linear'</span>,<span class="string">'rbf'</span>,<span class="string">'poly'</span>,<span class="string">'sigmoid'</span>,<span class="string">'user'</span>}, <span class="string">'Kernel type. Linear, or Non-linear kernel types: Radial Basis Functions (general-purpose),  Polynomial (rarely preferred), Sigmoid (usually overly simple), User (user-defined kernel from kernel.h).'</span>,<span class="string">'cat'</span>,<span class="string">'Core Parameters'</span>), <span class="keyword">...</span>
0083     arg({<span class="string">'g'</span>,<span class="string">'RBFScale'</span>,<span class="string">'gamma'</span>}, search(2.^(-16:2:4)), [], <span class="string">'Scaling parameter of the RBF kernel. Should match the size of structures in the data; A reasonable range is 2.^(-16:2:4).'</span>,<span class="string">'cat'</span>,<span class="string">'Core Parameters'</span>), <span class="keyword">...</span>
0084     arg({<span class="string">'d'</span>,<span class="string">'PolyDegree'</span>}, uint32(3), [], <span class="string">'Degree for the polynomial kernel.'</span>,<span class="string">'cat'</span>,<span class="string">'Core Parameters'</span>), <span class="keyword">...</span>
0085     arg({<span class="string">'etube'</span>,<span class="string">'EpsilonTube'</span>,<span class="string">'tube'</span>}, 0.1, [], <span class="string">'Epsilon tube width for regression.'</span>,<span class="string">'cat'</span>,<span class="string">'Core Parameters'</span>), <span class="keyword">...</span>
0086     arg({<span class="string">'rbalance'</span>,<span class="string">'CostBalance'</span>,<span class="string">'balance'</span>}, 1, [], <span class="string">'Relative cost of per-class errors. The factor by which training errors on positive examples outweight errors on negative examples.'</span>,<span class="string">'cat'</span>,<span class="string">'Core Parameters'</span>), <span class="keyword">...</span>
0087     <span class="keyword">...</span>
0088     arg({<span class="string">'s'</span>,<span class="string">'SigmoidPolyScale'</span>}, 1, [], <span class="string">'Scale of sigmoid/polynomial kernel.'</span>,<span class="string">'cat'</span>,<span class="string">'Miscellaneous'</span>), <span class="keyword">...</span>
0089     arg({<span class="string">'r'</span>,<span class="string">'SigmoidPolyBias'</span>}, 1, [], <span class="string">'Bias of sigmoid/polynomial kernel.'</span>,<span class="string">'cat'</span>,<span class="string">'Miscellaneous'</span>), <span class="keyword">...</span>
0090     arg({<span class="string">'u'</span>,<span class="string">'UserParameter'</span>}, <span class="string">'1'</span>, [], <span class="string">'User-defined kernel parameter.'</span>,<span class="string">'cat'</span>,<span class="string">'Miscellaneous'</span>,<span class="string">'type'</span>,<span class="string">'char'</span>,<span class="string">'shape'</span>,<span class="string">'row'</span>), <span class="keyword">...</span>
0091     arg({<span class="string">'bias'</span>,<span class="string">'Bias'</span>}, false, [], <span class="string">'Include a bias term. Only implemented for linear kernel.'</span>,<span class="string">'cat'</span>,<span class="string">'Miscellaneous'</span>), <span class="keyword">...</span>
0092     arg({<span class="string">'scaling'</span>,<span class="string">'Scaling'</span>}, <span class="string">'std'</span>, {<span class="string">'none'</span>,<span class="string">'center'</span>,<span class="string">'std'</span>,<span class="string">'minmax'</span>,<span class="string">'whiten'</span>}, <span class="string">'Pre-scaling of the data. For the regulariation to work best, the features should either be naturally scaled well, or be artificially scaled.'</span>,<span class="string">'cat'</span>,<span class="string">'Miscellaneous'</span>), <span class="keyword">...</span>
0093     arg({<span class="string">'clean'</span>,<span class="string">'CleanUp'</span>}, false, [], <span class="string">'Remove inconsistent training examples.'</span>,<span class="string">'cat'</span>,<span class="string">'Miscellaneous'</span>), <span class="keyword">...</span>
0094     arg({<span class="string">'epsi'</span>,<span class="string">'Epsilon'</span>,<span class="string">'eps'</span>}, 0.1, [], <span class="string">'Tolerated solution accuracy.'</span>,<span class="string">'cat'</span>,<span class="string">'Miscellaneous'</span>), <span class="keyword">...</span>
0095     arg({<span class="string">'verbose'</span>,<span class="string">'Verbose'</span>}, false, [], <span class="string">'Show diagnostic output.'</span>,<span class="string">'cat'</span>,<span class="string">'Miscellaneous'</span>));
0096 
0097 <span class="keyword">if</span> is_search(cost)
0098     cost = 1; <span class="keyword">end</span>
0099 <span class="keyword">if</span> is_search(g)
0100     g = 0.3; <span class="keyword">end</span>
0101 
0102 <span class="comment">% find the class labels</span>
0103 classes = unique(targets);
0104 <span class="keyword">if</span> length(classes) &gt; 2
0105     <span class="comment">% in this case we use the voter</span>
0106     model = <a href="ml_trainvote.html" class="code" title="function model = ml_trainvote(trials, targets, votingscheme, learner, predictor, varargin)">ml_trainvote</a>(trials,targets,<span class="string">'1v1'</span>,@<a href="ml_trainsvmlight.html" class="code" title="function model = ml_trainsvmlight(varargin)">ml_trainsvmlight</a>,@<a href="ml_predictsvmlight.html" class="code" title="function pred = ml_predictsvmlight(trials, model)">ml_predictsvmlight</a>,varargin{:});
0107 <span class="keyword">elseif</span> length(classes) == 1
0108     error(<span class="string">'BCILAB:only_one_class'</span>,<span class="string">'Your training data set has no trials for one of your classes; you need at least two classes to train a classifier.\n\nThe most likely reasons are that one of your target markers does not occur in the data, or that all your trials of a particular class are concentrated in a single short segment of your data (10 or 20 percent). The latter would be a problem with the experiment design.'</span>);
0109 <span class="keyword">else</span>    
0110     <span class="comment">% scale the data</span>
0111     sc_info = hlp_findscaling(trials,scaling);
0112     trials = hlp_applyscaling(trials,sc_info);
0113     
0114     <span class="comment">% remap target labels to -1,+1</span>
0115     targets(targets==classes(1)) = -1;
0116     targets(targets==classes(2)) = +1;
0117 
0118     <span class="comment">% rewrite sme string args to numbers</span>
0119     ptype = hlp_rewrite(ptype,<span class="string">'classification'</span>,<span class="string">'c'</span>,<span class="string">'regression'</span>,<span class="string">'r'</span>,<span class="string">'ranking'</span>,<span class="string">'p'</span>); <span class="comment">%#ok&lt;*NODEF&gt;</span>
0120     kernel = hlp_rewrite(kernel,<span class="string">'linear'</span>,0,<span class="string">'poly'</span>,1,<span class="string">'rbf'</span>,2,<span class="string">'sigmoid'</span>,3,<span class="string">'user'</span>,4);
0121         
0122     <span class="comment">% build the arguments</span>
0123     args = sprintf(<span class="string">'-z %s -c %f -v %d -w %f -j %f, -b %d -i %d -e %f -t %d -d %d -g %f -s %f -r %f -u %s'</span>, <span class="keyword">...</span>
0124         ptype,cost,verbose,etube,rbalance,bias,clean,epsi,kernel,d,g,s,r,u);
0125 
0126     <span class="comment">% run the command</span>
0127     model = hlp_diskcache(<span class="string">'predictivemodels'</span>,@svmlearn,trials,targets,args);
0128     model.sc_info = sc_info;
0129     model.classes = classes;
0130 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Tue 20-Aug-2013 03:44:10 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>