<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of ParadigmDataflowSimplified</title>
  <meta name="keywords" content="ParadigmDataflowSimplified">
  <meta name="description" content="">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../index.html">Home</a> &gt;  <a href="#">code</a> &gt; <a href="index.html">paradigms</a> &gt; ParadigmDataflowSimplified.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../index.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for code/paradigms&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>ParadigmDataflowSimplified
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong></strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>This is a script file. </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment"></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="ParadigmBaseSimplified.html" class="code" title="">ParadigmBaseSimplified</a>	</li><li><a href="ParadigmDataflowSimplified.html" class="code" title="">ParadigmDataflowSimplified</a>	</li></ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="ParadigmBandpower.html" class="code" title="">ParadigmBandpower</a>	</li><li><a href="ParadigmCSP.html" class="code" title="">ParadigmCSP</a>	</li><li><a href="ParadigmDAL.html" class="code" title="">ParadigmDAL</a>	</li><li><a href="ParadigmDALERP.html" class="code" title="">ParadigmDALERP</a>	</li><li><a href="ParadigmDALOSC.html" class="code" title="">ParadigmDALOSC</a>	</li><li><a href="ParadigmDataflowSimplified.html" class="code" title="">ParadigmDataflowSimplified</a>	</li><li><a href="ParadigmFBCSP.html" class="code" title="">ParadigmFBCSP</a>	</li><li><a href="ParadigmMTCSP.html" class="code" title="">ParadigmMTCSP</a>	</li><li><a href="ParadigmRCSP.html" class="code" title="">ParadigmRCSP</a>	</li><li><a href="ParadigmRSSD.html" class="code" title="">ParadigmRSSD</a>	</li><li><a href="ParadigmSIFT.html" class="code" title="">ParadigmSIFT</a>	</li><li><a href="ParadigmSpecCSP.html" class="code" title="">ParadigmSpecCSP</a>	</li><li><a href="ParadigmSpectralmeans.html" class="code" title="">ParadigmSpectralmeans</a>	</li><li><a href="ParadigmTFR.html" class="code" title="">ParadigmTFR</a>	</li><li><a href="ParadigmWindowmeans.html" class="code" title="">ParadigmWindowmeans</a>	</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function defaults = preprocessing_defaults(self)</a></li><li><a href="#_sub2" class="code">function featuremodel = feature_adapt(self,varargin)</a></li><li><a href="#_sub3" class="code">function features = feature_extract(self,signal,featuremodel)</a></li><li><a href="#_sub4" class="code">function conditioningmodel = feature_adapt_conditioning(self,varargin)</a></li><li><a href="#_sub5" class="code">function [features,targets] = feature_apply_conditioning(self,features,targets,conditioningmodel)</a></li><li><a href="#_sub6" class="code">function defaults = machine_learning_defaults(self)</a></li><li><a href="#_sub7" class="code">function layout = dialog_layout_defaults(self)</a></li><li><a href="#_sub8" class="code">function visualize_model(self,parent,featuremodel,predictivemodel)</a></li><li><a href="#_sub9" class="code">function tf = needs_voting(self)</a></li><li><a href="#_sub10" class="code">function [featuremodel,conditioningmodel,predictivemodel] = calibrate_prediction_function(self,varargin)</a></li><li><a href="#_sub11" class="code">function outputs = apply_prediction_function(self,signal,featuremodel,conditioningmodel,predictivemodel)</a></li><li><a href="#_sub12" class="code">function model = calibrate_simple(self,varargin)</a></li><li><a href="#_sub13" class="code">function outputs = predict_simple(self,signal,model)</a></li><li><a href="#_sub14" class="code">function visualize(self,model,varargin)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 classdef <a href="ParadigmDataflowSimplified.html" class="code" title="">ParadigmDataflowSimplified</a> &lt; <a href="ParadigmBaseSimplified.html" class="code" title="">ParadigmBaseSimplified</a>
0002     <span class="comment">% Base class for simple dataflow-oriented BCI paradigms.</span>
0003     <span class="comment">%</span>
0004     <span class="comment">% This is the base class that almost all traditional (non-multi-subject and single-stream) BCI</span>
0005     <span class="comment">% paradigms should be derived from.</span>
0006     <span class="comment">%</span>
0007     <span class="comment">% Most such BCI paradigms do the following during online processing: The raw input signal is</span>
0008     <span class="comment">% first sent through a series of filter steps (i.e., signal processing), each here implemented</span>
0009     <span class="comment">% as a flt_***.m plugin function (e.g. spatial and spectral filters). To compute an estimate of</span>
0010     <span class="comment">% (or inference about) the cognitive state of the user at a particular time point in the signal,</span>
0011     <span class="comment">% a &quot;prediction function&quot; is invoked on a segment of that signal. It then typically first</span>
0012     <span class="comment">% extracts a set of features from the signal (yielding a feature vector or matrix) and then</span>
0013     <span class="comment">% passes on the feature vector to a machine learning plugin's prediction function (an</span>
0014     <span class="comment">% ml_predict***.m function) to obtain the desired output. The feature extraction and predictive</span>
0015     <span class="comment">% mapping can also be implemented as a custom combined step without going through a machine</span>
0016     <span class="comment">% learning plugin.</span>
0017     <span class="comment">%</span>
0018     <span class="comment">% The prediction function performs its processing with the help of a (separately computed)</span>
0019     <span class="comment">% &quot;predictive model&quot;, which is a MATLAB struct that contains any parameters necessary for online</span>
0020     <span class="comment">% processing. A predictive model is computed in a dedicated calibration (a.k.a. 'training') step</span>
0021     <span class="comment">% based on a calibration recording. Such a recording is typically a 10-60 minute EEGLAB data set</span>
0022     <span class="comment">% which is annotated with target markers that indicate the desired output of the BCI at various</span>
0023     <span class="comment">% time points. During calibration, both the signal processing stages, the feature extraction</span>
0024     <span class="comment">% function, as well as the machine learning part may be adapted to optimally predict the desired</span>
0025     <span class="comment">% outputs for some given input signal data. In a dataflow model, calibration consists of first</span>
0026     <span class="comment">% applying a (custom-defined) sequence of pre-processing (i.e. filter) steps to the raw signal,</span>
0027     <span class="comment">% then optionally adapting any features based on the contents of the processed signal or</span>
0028     <span class="comment">% additional user parameters, and finally applying a machine learning plugin function (an</span>
0029     <span class="comment">% ml_train***.m function) to learn a statistical map from the (labeled) feature vectors (as</span>
0030     <span class="comment">% previously extracted from the data) onto the desired outputs (= labels). The feature</span>
0031     <span class="comment">% adaptation / extraction and machine learning can also be implemented in a signal combined step,</span>
0032     <span class="comment">% without the need to go through a separate plugin function.</span>
0033     <span class="comment">%</span>
0034     <span class="comment">% Derive from this class if your processing consists of a chain of filter steps followed by a</span>
0035     <span class="comment">% (possibly adaptive) feature extraction, followed by a machine learning step, and if in your</span>
0036     <span class="comment">% paradigm, calibration is done based on a single data set (i.e. neither dataset collections nor</span>
0037     <span class="comment">% stream bundles are handled meaningfully by it).</span>
0038     <span class="comment">%</span>
0039     <span class="comment">% * you supply a feature_adapt() function which takes a signal and arbitrary optional arguments</span>
0040     <span class="comment">%   and packages any information needed by the feature-extraction stage into a &quot;feature model&quot;</span>
0041     <span class="comment">%   struct (e.g. user parameters or signal-dependent parameters).</span>
0042     <span class="comment">% * you supply a feature_extract() function which takes a signal and a previously computed feature</span>
0043     <span class="comment">%   model and extracts features for every trial in the signal.</span>
0044     <span class="comment">% * typically, you specify the default signal processing stages to apply before feature extraction</span>
0045     <span class="comment">%   and the default machine learning step to apply after feature extraction (both of which can be</span>
0046     <span class="comment">%   overridden by users of the paradigm), by overriding preprocessing_defaults() and/or</span>
0047     <span class="comment">%   machine_learning_defaults()</span>
0048     <span class="comment">%</span>
0049     <span class="comment">% * optionally, you specify a visualize_model function for the resulting model and a default</span>
0050     <span class="comment">%   specification for a configuration dialog (dialog_layout_defaults, see other paradigms for examples).</span>
0051     <span class="comment">%</span>
0052     <span class="comment">% * if your learning and prediction process (after signal processing) is non-traditional (e.g. you</span>
0053     <span class="comment">%   perform a computation that blends traditional feature extraction and machine learning, or</span>
0054     <span class="comment">%   the notion of data points in your machine learning differs from the marker-locked trials in the</span>
0055     <span class="comment">%   calibration data), you may implement your own calibrate_prediction_function() and</span>
0056     <span class="comment">%   optionally apply_prediction_function() methods. In this case you may ignore the feature_adapt()</span>
0057     <span class="comment">%   and feature_extract() functions.</span>
0058     <span class="comment">%</span>
0059     <span class="comment">% Name:</span>
0060     <span class="comment">%   Basic Dataflow (abstract)</span>
0061     <span class="comment">%</span>
0062     <span class="comment">%                            Christian Kothe, Swartz Center for Computational Neuroscience, UCSD</span>
0063     <span class="comment">%                            2011-08-28</span>
0064     
0065     methods
0066         
0067         <a name="_sub0" href="#_subfunctions" class="code">function defaults = preprocessing_defaults(self)</a>
0068             <span class="comment">% Optionally override this function to specify custom defaults for the preprocessing</span>
0069             <span class="comment">% pipeline (flt_pipeline).</span>
0070             <span class="comment">%</span>
0071             <span class="comment">% Out:</span>
0072             <span class="comment">%   Defaults : cell array of name-value pairs (or a struct) controlling the default settings</span>
0073             <span class="comment">%              for flt_pipeline (see this function for detailed information on the syntax).</span>
0074             <span class="comment">%</span>
0075             <span class="comment">% Notes:</span>
0076             <span class="comment">%   Here you can define which of the available signal processing plugins you want to</span>
0077             <span class="comment">%   apply to the raw input signal (e.g. FIR band-pass, epoch extraction, resampling),</span>
0078             <span class="comment">%   and what parameters should be used to call them. This is done by returning a cell</span>
0079             <span class="comment">%   array of the form {filtername, parameters, filtername, parameters, ...} where the</span>
0080             <span class="comment">%   filtername is either the name of a flt_*** function or its human-readable (and</span>
0081             <span class="comment">%   CamelCase) name; any filter declares such a name in a declare_properties(...) line</span>
0082             <span class="comment">%   at the beginning of the function. The CamelCase name is recommended here for</span>
0083             <span class="comment">%   consistency with the GUI display of these filters. The parameters of the filter are</span>
0084             <span class="comment">%   most generally a cell array of the function's inputs, or, if only one input is</span>
0085             <span class="comment">%   passed, may also be just the value itself (e.g. some numeric array). This is also</span>
0086             <span class="comment">%   the same way in which the filter stages to apply can be passed to flt_pipeline.m</span>
0087             <span class="comment">%   (which is the &quot;dispatch function used internally by ParadigmDataflowSimplified,</span>
0088             <span class="comment">%   and which contains some additional documentation about the syntax allowed here).</span>
0089             <span class="comment">%</span>
0090             <span class="comment">%   The order in which filters are listed here is ignored, and instead usually</span>
0091             <span class="comment">%   auto-determined based on some common ordering rules (each filter declares some</span>
0092             <span class="comment">%   required and/or preferred ordering relationships); it may however be overridden partially</span>
0093             <span class="comment">%   or completely by appending a 'FilterOrdering',{'filtername','filtername','filtername', ...}</span>
0094             <span class="comment">%   name-value pair to the defaults cell array that is returned here.</span>
0095             <span class="comment">%</span>
0096             <span class="comment">%   The majority of paradigms perform some continuous signal processing (e.g. IIR</span>
0097             <span class="comment">%   frequency filtering), followed by extraction of epochs around target markers</span>
0098             <span class="comment">%   (implemented by the 'EpochExtraction' filter, see set_makepos.m), possibly followed</span>
0099             <span class="comment">%   by some further epoch-based signal processing (e.g. fourier transform). While it is</span>
0100             <span class="comment">%   possible to perform all processing on continuous data (in this case likely using a</span>
0101             <span class="comment">%   &quot;target channel&quot; instead of target markers), this is currently not a common practice</span>
0102             <span class="comment">%   in BCILAB, so it is more probable that the support for such processing is</span>
0103             <span class="comment">%   insufficiently documented and perhaps partially untested.</span>
0104             <span class="comment">%</span>
0105             <span class="comment">%   While this function defines the default signal processing setup, the user can</span>
0106             <span class="comment">%   partially or completely override the setup when he/she configures the paradigm into</span>
0107             <span class="comment">%   a custom approach (by passing a custom 'SignalProcessing' argument to the paradigm</span>
0108             <span class="comment">%   during calibration).</span>
0109             
0110             <span class="comment">% by default, here epochs of 1 second length will be extracted relative to the target</span>
0111             <span class="comment">% markers (beginning 0.5 seconds before each target marker, and ending 0.5 seconds after</span>
0112             <span class="comment">% it). See set_targetmarkers for an explanation of what a target marker is.</span>
0113             defaults = {<span class="string">'EpochExtraction'</span>,{<span class="string">'TimeWindow'</span>,[-0.5 0.5]}};
0114         <span class="keyword">end</span>
0115         
0116         
0117         <a name="_sub1" href="#_subfunctions" class="code">function featuremodel = feature_adapt(self,varargin)</a>
0118             <span class="comment">% Override this function if you have a custom feature adaption step or need to declare</span>
0119             <span class="comment">% custom feature extraction parameters.</span>
0120             <span class="comment">% FeatureModel = feature_adapt(Signal, Arguments...)</span>
0121             <span class="comment">%</span>
0122             <span class="comment">% This function is called during calibration on the already pre-processed data. The</span>
0123             <span class="comment">% output of this function is a &quot;featuremodel&quot; struct that describes the parameters with</span>
0124             <span class="comment">% which feature extraction shall be done on the data for online processing (as well as</span>
0125             <span class="comment">% for the subsequent feature extraction during calibration, whose outputs feed into</span>
0126             <span class="comment">% machine learning). Any user parameters that shall go into feature extraction should be</span>
0127             <span class="comment">% declared here (using the arg_define() facility), as well as a parameter named 'Signal'</span>
0128             <span class="comment">% which is the pre-processed data. The signal may be used to adapt some of the feature-</span>
0129             <span class="comment">% extraction parameters in data-dependent (and possibly supervised, i.e. also</span>
0130             <span class="comment">% label-dependent) manner. See ParadigmCSP.m for a case with supervised feature adaptation</span>
0131             <span class="comment">% and ParadigmWindowmeans.m for a case without data-driven feature adaptation.</span>
0132             <span class="comment">%</span>
0133             <span class="comment">% The code below demonstrates how to declare a simple feature-extraction argument as</span>
0134             <span class="comment">% well as the (mandatory) signal argument, and how the arguments are usually documented</span>
0135             <span class="comment">% in paradigms. All of these arguments are accessible as sub-arguments of the</span>
0136             <span class="comment">% Prediction.FeatureExtraction argument of the paradigm.</span>
0137             <span class="comment">%</span>
0138             <span class="comment">% In:</span>
0139             <span class="comment">%   Signal : a signal as processed by the pre-processing pipeline (flt_pipeline);</span>
0140             <span class="comment">%            this is in almost all configurations an expoched data set</span>
0141             <span class="comment">%</span>
0142             <span class="comment">%   GroupInto : Feature grouping. This controls how the processed data in each epoch is</span>
0143             <span class="comment">%               vectorized into a feature vector; either the resulting vector has a block</span>
0144             <span class="comment">%               with all channels of the first sample in succession, followed by a block</span>
0145             <span class="comment">%               with all channels of the second sample and so on (channel grouping), or a</span>
0146             <span class="comment">%               block with all samples for the first channel, followed by a block with all</span>
0147             <span class="comment">%               samples of the second channel, and so on (samples grouping).</span>
0148             <span class="comment">%</span>
0149             <span class="comment">%               GroupInto is a sample user parameter; other feature extraction functions may</span>
0150             <span class="comment">%               define arbitrary other parameters (or none -- see some other paradigms for</span>
0151             <span class="comment">%               examples).</span>
0152             <span class="comment">%</span>
0153             <span class="comment">% Out:</span>
0154             <span class="comment">%   FeatureModel : an adapted model that can subsequently be used for feature extraction</span>
0155             <span class="comment">%                  (here: an empty struct)</span>
0156             <span class="comment">%</span>
0157             <span class="comment">% Notes:</span>
0158             <span class="comment">%   Overridden functions should declare their arguments using arg_define().</span>
0159             
0160             arg_define(varargin, <span class="keyword">...</span>
0161                 arg_norep({<span class="string">'signal'</span>,<span class="string">'Signal'</span>}), <span class="keyword">...</span>
0162                 arg({<span class="string">'group_into'</span>,<span class="string">'GroupInto'</span>},<span class="string">'channels'</span>,{<span class="string">'channels'</span>,<span class="string">'samples'</span>,<span class="string">'matrix'</span>},<span class="string">'Feature grouping. This controls how the processed data in each epoch is vectorized into a feature vector; either the resulting vector has a block with all channels of the first sample in succession, followed by a block with all channels of the second sample and so on (channel grouping), or a block with all samples for the first channel, followed by a block with all samples of the second channel, and so on (samples grouping).'</span>));
0163             
0164             <span class="comment">% pack our group_into parameter into the featuremodel for later use in feature_extract().</span>
0165             featuremodel.group_into = group_into;
0166         <span class="keyword">end</span>
0167         
0168         
0169         <a name="_sub2" href="#_subfunctions" class="code">function features = feature_extract(self,signal,featuremodel)</a>
0170             <span class="comment">% Override this function to implement your feature extraction step.</span>
0171             <span class="comment">% Features = feature_extract(Signal, FeatureModel, Arguments...)</span>
0172             <span class="comment">%</span>
0173             <span class="comment">% This function implements the paradigm's feature extraction: given a pre-processed</span>
0174             <span class="comment">% signal and a (previously determined) featuremodel, return an array of feature vectors</span>
0175             <span class="comment">% (or in rare cases feature matrices) for subsequent use by the machine learning.</span>
0176             <span class="comment">%</span>
0177             <span class="comment">% This function is must return one feature vector for each target value in the signal.</span>
0178             <span class="comment">% Thus, if the signal is epoched, a feature vector must be returned for each epoch</span>
0179             <span class="comment">% (during online use, this function will usually only see a single epoch). If the signal</span>
0180             <span class="comment">% is continuous (i.e., no EpochExtraction was used in the filter setup), one feature</span>
0181             <span class="comment">% vector should be be returned for each sample in the signal (and - importantly - the</span>
0182             <span class="comment">% target channel, if any, must be ignored).</span>
0183             <span class="comment">%</span>
0184             <span class="comment">% In:</span>
0185             <span class="comment">%   Signal : a signal as processed by the preprocessing pipeline (flt_pipeline);</span>
0186             <span class="comment">%            this is in almost all configurations an epoched data set</span>
0187             <span class="comment">%</span>
0188             <span class="comment">%   FeatureModel : the adapted feature model, as specified by the FeatureAdaption step (if</span>
0189             <span class="comment">%                  any)</span>
0190             <span class="comment">%</span>
0191             <span class="comment">% Out:</span>
0192             <span class="comment">%   Features : extracted feature vectors (usually one per trial / target value in the data)</span>
0193             <span class="comment">%              these may be in any form supported by ml_train (and the default training function</span>
0194             <span class="comment">%              in particular), most frequently [#Trials x #Features]</span>
0195             <span class="comment">%</span>
0196             
0197             <span class="keyword">switch</span> featuremodel.group_into
0198                 <span class="keyword">case</span> <span class="string">'channels'</span>
0199                     <span class="comment">% group by channels</span>
0200                     features = squeeze(reshape(signal.data,[],1,size(signal.data,3)))';
0201                 <span class="keyword">case</span> <span class="string">'samples'</span>
0202                     <span class="comment">% group by samples</span>
0203                     features = squeeze(reshape(permute(signal.data,[2 1 3]),[],1,size(signal.data,3)))';
0204                 <span class="keyword">case</span> <span class="string">'matrix'</span>
0205                     <span class="comment">% pass on feature matrices</span>
0206                     features = signal.data;
0207             <span class="keyword">end</span>
0208         <span class="keyword">end</span>
0209         
0210         
0211         <a name="_sub3" href="#_subfunctions" class="code">function conditioningmodel = feature_adapt_conditioning(self,varargin)</a>
0212             <span class="comment">% Override this function if you need to implement feature conditioning steps.</span>
0213             <span class="comment">% ConditioningModel = feature_adapt_conditioning(Signal, Arguments...)</span>
0214             <span class="comment">%</span>
0215             <span class="comment">% This function serves to simplify feature representations so as to be better suited for</span>
0216             <span class="comment">% use with classifiers. This type of processing is not frequently used and the</span>
0217             <span class="comment">% default implementation currently handles only some basic cases.</span>
0218             <span class="comment">%</span>
0219             <span class="comment">% In:</span>
0220             <span class="comment">%   Features : feature representations, as allowed by ml_train</span>
0221             <span class="comment">%</span>
0222             <span class="comment">%   Targets : target-value representations, as allowed by ml_train</span>
0223             <span class="comment">%</span>
0224             <span class="comment">%   PruneTrivialFeatures : Prune trivial features. This prunes features which are constant</span>
0225             <span class="comment">%                          across the whole training set. Currently restricted to vectorized features. (default: false)</span>
0226             <span class="comment">%</span>
0227             <span class="comment">%   EqualizeClasses : ensure that the number of exemplars per class is equal by reducing trials.</span>
0228             <span class="comment">%                     (default: false)</span>
0229             <span class="comment">%</span>
0230             <span class="comment">% Out:</span>
0231             <span class="comment">%   ConditioningModel : a model that holds the parameters for feature conditioning.</span>
0232             <span class="comment">%</span>
0233             <span class="comment">% Notes:</span>
0234             <span class="comment">%   Overridden functions should declare their arguments using arg_define().</span>
0235             
0236             args = arg_define(varargin, <span class="keyword">...</span>
0237                 arg_norep({<span class="string">'features'</span>,<span class="string">'Features'</span>}), <span class="keyword">...</span>
0238                 arg_norep({<span class="string">'targets'</span>,<span class="string">'Targets'</span>}), <span class="keyword">...</span>
0239                 arg({<span class="string">'prune_trivial'</span>,<span class="string">'PruneTrivialFeatures'</span>},false,[],<span class="string">'Prune trivial features. This prunes features which are constant across the whole training set.'</span>), <span class="keyword">...</span>
0240                 arg({<span class="string">'equalize_classes'</span>,<span class="string">'EqualizeClasses'</span>},false,[],<span class="string">'Equalize class ratios. This removes trials of the larger class(es) such that the number of exemplars for all classes is equal.'</span>));
0241             
0242             features = args.features;
0243             targets = args.targets;
0244             
0245             <span class="keyword">if</span> args.prune_trivial
0246                 conditioningmodel.prune_indices = find(sum(bsxfun(@minus,features(1,:),features))==0); <span class="keyword">end</span>
0247             <span class="keyword">if</span> args.equalize_classes
0248                 classes = unique(targets);
0249                 num_exemplars = sum(bsxfun(@eq,classes',targets));
0250                 reduce_to = min(num_exemplars);
0251                 subset = {};
0252                 <span class="keyword">for</span> k = 1:length(classes)
0253                     shuffled = shuffle(find(targets==classes(k)));
0254                     subset{k} = shuffled(1:reduce_to);
0255                 <span class="keyword">end</span>
0256                 subset = sort(vertcat(subset{:}));
0257                 conditioningmodel.subset = subset;
0258             <span class="keyword">end</span>
0259             
0260             conditioningmodel.prune_trivial = args.prune_trivial;
0261             conditioningmodel.equalize_classes = args.equalize_classes;
0262         <span class="keyword">end</span>
0263         
0264         <a name="_sub4" href="#_subfunctions" class="code">function [features,targets] = feature_apply_conditioning(self,features,targets,conditioningmodel)</a>
0265             <span class="comment">% This function implements the actual feature conditioning.</span>
0266             <span class="comment">% [Features,Targets] = feature_apply_conditioning(Features,Targets,ConditioningModel)</span>
0267             <span class="comment">%</span>
0268             <span class="comment">% In:</span>
0269             <span class="comment">%   Features : feature representations, as allowed by ml_train</span>
0270             <span class="comment">%</span>
0271             <span class="comment">%   Targets : target-value representations, as allowed by ml_train (can be empty)</span>
0272             <span class="comment">%</span>
0273             <span class="comment">%   ConditioningModel : the model generated by feature_adapt_conditioning</span>
0274             <span class="comment">%</span>
0275             <span class="comment">% Out:</span>
0276             <span class="comment">%   Features : conditioned feature representations, as allowed by ml_train</span>
0277             <span class="comment">%</span>
0278             <span class="comment">%   Targets : conditioned target-value representations, as allowed by ml_train</span>
0279             
0280             <span class="keyword">if</span> conditioningmodel.prune_trivial
0281                 features(:,conditioningmodel.prune_indices) = []; <span class="keyword">end</span>
0282             <span class="keyword">if</span> conditioningmodel.equalize_classes
0283                 features = features(conditioningmodel.subset,:);
0284                 <span class="keyword">if</span> ~isempty(targets)
0285                     targets = targets(conditioningmodel.subset); <span class="keyword">end</span>
0286             <span class="keyword">end</span>
0287         <span class="keyword">end</span>
0288         
0289         <a name="_sub5" href="#_subfunctions" class="code">function defaults = machine_learning_defaults(self)</a>
0290             <span class="comment">% Optionally override this function to specify custom defaults for the machine learning</span>
0291             <span class="comment">% step (ml_train***.m).</span>
0292             <span class="comment">%</span>
0293             <span class="comment">% Similarly to preprocessing_defaults(), this function specifies the default settings</span>
0294             <span class="comment">% to use for machine learning. Usually, this involves selecting the machine learning plugin</span>
0295             <span class="comment">% to apply via its acronym (the *** in the respective ml_train***.m) and optionally</span>
0296             <span class="comment">% declaring the default user arguments to use for it, typically as name-value pairs.</span>
0297             <span class="comment">% These arguments will be processed by the function ml_train.m, which is the dispatch</span>
0298             <span class="comment">% function used internally by ParadigmDataflowSimplified.</span>
0299             <span class="comment">%</span>
0300             <span class="comment">% Out:</span>
0301             <span class="comment">%   Defaults : cell array of {Learner, Arguments...} for ml_train; where Learner is the shortcut</span>
0302             <span class="comment">%              name of the respective learning function (e.g. 'logreg' for ml_trainlogreg), and</span>
0303             <span class="comment">%              and the remaining elements are arguments that will be passed as user arguments</span>
0304             <span class="comment">%              into the respective machine learning function (usually as name-value pairs,</span>
0305             <span class="comment">%              see ParadigmWPI.m or ParadigmRSSD.m for examples).</span>
0306             
0307             <span class="comment">% by default, LDA (Linear Discriminant Analysis, ml_trainlda) is used with no arguments;</span>
0308             <span class="comment">% if called with no arguments, ml_trainlda will run &quot;shrinkage LDA&quot; which is a good default</span>
0309             <span class="comment">% linear classifier</span>
0310             defaults = {<span class="string">'lda'</span>};
0311         <span class="keyword">end</span>
0312         
0313         
0314         <a name="_sub6" href="#_subfunctions" class="code">function layout = dialog_layout_defaults(self)</a>
0315             <span class="comment">% Optionally override this function to specify a custom GUI dialog layout.</span>
0316             <span class="comment">%</span>
0317             <span class="comment">% Each BCI paradigm should ideally have a dialog that exposes its key user-configurable</span>
0318             <span class="comment">% settings (this dialog is brought by the GUI). In BCILAB, the dialog is auto-generated</span>
0319             <span class="comment">% from the arguments of calibrate_simple() (actually most generally calibrate()) and</span>
0320             <span class="comment">% their sub-arguments. These are rich argument declarations made via arg_define</span>
0321             <span class="comment">% (comprising both the names, default values, extended help texts and optionally valid</span>
0322             <span class="comment">% ranges of any parameter of the paradigm).</span>
0323             <span class="comment">%</span>
0324             <span class="comment">% This function lists a selection of arguments (by their declared CamelCase names) as a</span>
0325             <span class="comment">% cell array, in the order of appearance in the dialog (one argument typically</span>
0326             <span class="comment">% translates into a one-line label/widget combo, except if it has sub-arguments),</span>
0327             <span class="comment">% possibly interleaved with '' separators (translating into blank lines in the dialog for</span>
0328             <span class="comment">% optical separation). Sub-arguments of the top-level arguments in calibrate_simple() can</span>
0329             <span class="comment">% be accessed by dot notation (as in 'Prediction.FeatureExtraction.GroupInto).</span>
0330             <span class="comment">%</span>
0331             <span class="comment">% Out:</span>
0332             <span class="comment">%   Layout : config layout; This is a cell array of parameter names, optionally with '' interleaved.</span>
0333             <span class="comment">%            Each parameter name results in one or more lines (and corresponding entry</span>
0334             <span class="comment">%            fields) inserted into the GUI dialog for the respective parameter (multiple</span>
0335             <span class="comment">%            lines if the denoted parameter has sub-parameters). Sub-parameters of a</span>
0336             <span class="comment">%            parameter can be referred to by means of dot notation. '' entries generate</span>
0337             <span class="comment">%            blank lines (i.e. spacing) in the dialog. The variable names are those that</span>
0338             <span class="comment">%            are defined (and exposed) by the calibrate_simple() function.</span>
0339             
0340             layout = {<span class="string">'SignalProcessing'</span>,<span class="string">''</span>,<span class="string">'Prediction.FeatureExtraction'</span>,<span class="string">''</span>,<span class="string">'Prediction.MachineLearning.Learner'</span>};
0341         <span class="keyword">end</span>
0342         
0343         
0344         <a name="_sub7" href="#_subfunctions" class="code">function visualize_model(self,parent,featuremodel,predictivemodel) </a><span class="comment">%#ok&lt;*INUSD&gt;</span>
0345             <span class="comment">% Optionally override this function to implement your visualization code</span>
0346             <span class="comment">% visualize(Parent,FeatureModel,PredictiveModel)</span>
0347             <span class="comment">%</span>
0348             <span class="comment">% In:</span>
0349             <span class="comment">%   Parent : parent window / figure</span>
0350             <span class="comment">%</span>
0351             <span class="comment">%   FeatureModel : a feature model as generated by feature_adapt and as understood by</span>
0352             <span class="comment">%                  feature_extract</span>
0353             <span class="comment">%</span>
0354             <span class="comment">%   PredictiveModel : a predictive model as generated by ml_train and as understood by</span>
0355             <span class="comment">%                     ml_predict</span>
0356             
0357             text(0.5,0.5,<span class="string">'This paradigm does not yet implement a visualization.'</span>,<span class="string">'HorizontalAlignment'</span>,<span class="string">'center'</span>);
0358         <span class="keyword">end</span>
0359         
0360         
0361         <a name="_sub8" href="#_subfunctions" class="code">function tf = needs_voting(self)</a>
0362             <span class="comment">% Override this function if your feature extraction only works for 2-class data (e.g.,</span>
0363             <span class="comment">% like CSP). This is the case when the feature adaptation is done in a supervised manner</span>
0364             <span class="comment">% (i.e. using labels) and can only deal with two classes.</span>
0365             tf = false;
0366         <span class="keyword">end</span>
0367         
0368         
0369         <a name="_sub9" href="#_subfunctions" class="code">function [featuremodel,conditioningmodel,predictivemodel] = calibrate_prediction_function(self,varargin)</a>
0370             <span class="comment">% Perform calibration of the prediction function; this includes everything except for signal</span>
0371             <span class="comment">% processing. This function can optionally be overridden if some custom feature-extraction /</span>
0372             <span class="comment">% machine learning data flow is desired; its user parameters may be arbitrarily redefined then.</span>
0373             <span class="comment">%</span>
0374             <span class="comment">% This function invokes the feature adaptation, feature extraction and machine learning</span>
0375             <span class="comment">% during the calibration phase (i.e. everything that is required to determine the</span>
0376             <span class="comment">% parameters of the BCI paradigm's prediction function).</span>
0377             <span class="comment">%</span>
0378             <span class="comment">% This function is what gives rise to the &quot;Prediction&quot; top-level argument of the paradigm;</span>
0379             <span class="comment">% as you see below, it has two sub-arguments: FeatureExtraction and MachineLearning, which</span>
0380             <span class="comment">% themselves are defined by feature_adapt() and ml_train().</span>
0381             <span class="comment">%</span>
0382             <span class="comment">% In:</span>
0383             <span class="comment">%   Signal : a signal as pre-processed according to the paradigm's pre-processing pipeline</span>
0384             <span class="comment">%</span>
0385             <span class="comment">%   FeatureExtraction : User parameters for the feature-extraction stage. These parameters</span>
0386             <span class="comment">%                       control how features are extracted from the filtered data before</span>
0387             <span class="comment">%                       they are passed int othe machine learning stage.</span>
0388             <span class="comment">%</span>
0389             <span class="comment">%   Conditioning : User parameters for an optional feature-conditioning stage. These parameters</span>
0390             <span class="comment">%                  control how features are remapped to features that are subsequently received</span>
0391             <span class="comment">%                  by the machine learning.</span>
0392             <span class="comment">%</span>
0393             <span class="comment">%   MachineLearning : Machine learning stage of the paradigm. Operates on the feature</span>
0394             <span class="comment">%                     vectors that are produced by the feature-extraction stage.</span>
0395             <span class="comment">%</span>
0396             <span class="comment">% Out:</span>
0397             <span class="comment">%   FeatureModel : a feature-extraction model as understood by apply_prediction_function()</span>
0398             <span class="comment">%                  or (if not otherwise customized) by the feature_extract() function</span>
0399             <span class="comment">%                  * special feature: if this contains a non-empty field named shape, this</span>
0400             <span class="comment">%                                     value will be passed on to the machine learning method</span>
0401             <span class="comment">%</span>
0402             <span class="comment">%   ConditioningModel : a model that is sandwiched between feature extraction and machine learning,</span>
0403             <span class="comment">%                       generated by feature_adapt_conditioning and understood by feature_apply_conditioning</span>
0404             <span class="comment">%</span>
0405             <span class="comment">%   PredictiveModel : a predictive model, as understood by apply_prediction_function() or</span>
0406             <span class="comment">%                     (if not otherwise customized) by the ml_predict() function</span>
0407             <span class="comment">%</span>
0408             <span class="comment">%</span>
0409             <span class="comment">% Notes:</span>
0410             <span class="comment">%   You may override this function if your prediction function blends traditional</span>
0411             <span class="comment">%   feature extraction and machine learning or otherwise makes this separation</span>
0412             <span class="comment">%   impractical (for example if you have an unusual mapping between training instances</span>
0413             <span class="comment">%   for machine learning and target values in the data set). This function should</span>
0414             <span class="comment">%   declare its arguments using arg_define().</span>
0415             
0416             args = arg_define(varargin, <span class="keyword">...</span>
0417                 arg_norep({<span class="string">'signal'</span>,<span class="string">'Signal'</span>}), <span class="keyword">...</span>
0418                 arg_sub({<span class="string">'fex'</span>,<span class="string">'FeatureExtraction'</span>},{},@self.feature_adapt,<span class="string">'Parameters for the feature-adaptation function. These parameters control how features are statistically adapted and extracted from the filtered data before they are passed into the machine learning stage.'</span>), <span class="keyword">...</span>
0419                 arg_sub({<span class="string">'cond'</span>,<span class="string">'Conditioning'</span>},{},@self.feature_adapt_conditioning,<span class="string">'Feature conditioning parameters. Allows to further process features for better usability with classifiers.'</span>), <span class="keyword">...</span>
0420                 arg_sub({<span class="string">'ml'</span>,<span class="string">'MachineLearning'</span>},{<span class="string">'Learner'</span>,self.machine_learning_defaults()},@ml_train,<span class="string">'Machine learning stage of the paradigm. Operates on the feature vectors that are produced by the feature-extraction stage.'</span>));
0421             
0422             <span class="comment">% adapt features if necessary</span>
0423             featuremodel = self.feature_adapt(<span class="string">'signal'</span>,args.signal, args.fex);
0424             <span class="keyword">if</span> isfield(featuremodel,<span class="string">'shape'</span>) &amp;&amp; ~isempty(featuremodel.shape)
0425                 <span class="comment">% check if the learner supports a shape parameter...</span>
0426                 <span class="keyword">if</span> isfield(args.ml.learner,<span class="string">'shape'</span>)
0427                     args.ml.learner.shape = featuremodel.shape; 
0428                 <span class="keyword">else</span>
0429                     warn_once(<span class="string">'ParadigmDataflowSimplified:ignoring_shape'</span>,<span class="string">'The learning function does not appear to support a shape parameter, but the paradigm prefers to supply one; ignoring the shape. This warning will not be shown again during this session.'</span>);
0430                 <span class="keyword">end</span>
0431             <span class="keyword">end</span>
0432             
0433             <span class="comment">% extract features</span>
0434             features = self.feature_extract(args.signal, featuremodel);
0435             
0436             <span class="comment">% extract target labels</span>
0437             targets = set_gettarget(args.signal);
0438             
0439             <span class="comment">% adapt and apply feature conditioning</span>
0440             conditioningmodel = self.feature_adapt_conditioning(<span class="string">'features'</span>,features,<span class="string">'targets'</span>,targets,args.cond);
0441             [features,targets] = self.feature_apply_conditioning(features,targets,conditioningmodel);
0442             
0443             <span class="comment">% run the machine learning stage</span>
0444             predictivemodel = ml_train(<span class="string">'data'</span>,{features,targets}, args.ml);
0445             
0446         <span class="keyword">end</span>
0447         
0448         
0449         <a name="_sub10" href="#_subfunctions" class="code">function outputs = apply_prediction_function(self,signal,featuremodel,conditioningmodel,predictivemodel)</a>
0450             <span class="comment">% Apply the feature extraction and final predictive mapping for every trial in the data</span>
0451             <span class="comment">% set (where a trial corresponds 1:1 to the outputs generated by set_gettarget() for the</span>
0452             <span class="comment">% given signal).</span>
0453             <span class="comment">%</span>
0454             <span class="comment">% This function basically is the BCI paradigm's prediction function - the only difference</span>
0455             <span class="comment">% is that the actual prediction function of ParadigmDataflowSimplified (below) may run</span>
0456             <span class="comment">% this function with different sets of parameters in a voting arrangement.</span>
0457             <span class="comment">%</span>
0458             <span class="comment">% In:</span>
0459             <span class="comment">%   Signal : a signal as pre-processed according to the paradigm's pre-processing pipeline</span>
0460             <span class="comment">%</span>
0461             <span class="comment">%   FeatureModel : a feature-extraction model as previously generated by</span>
0462             <span class="comment">%                  calibrate_prediction_function()</span>
0463             <span class="comment">%</span>
0464             <span class="comment">%   ConditioningModel : a feature-conditioning model as previously generated by</span>
0465             <span class="comment">%                       calibrate_prediction_function()</span>
0466             <span class="comment">%</span>
0467             <span class="comment">%   PredictiveModel : a predictive model, as previously generated by</span>
0468             <span class="comment">%                     calibrate_prediction_function()</span>
0469             <span class="comment">%</span>
0470             <span class="comment">% Out:</span>
0471             <span class="comment">%   Outputs : a prediction/estimate for the most recent time point in the data (or one for</span>
0472             <span class="comment">%             every epoch if the signal is epoched); see ml_predict for the allowed formats</span>
0473             <span class="comment">%</span>
0474             <span class="comment">% Notes:</span>
0475             <span class="comment">%   You may override this function if you have a predictive mapping that is not handled</span>
0476             <span class="comment">%   by any of the machine learning plugins (e.g. if you are using a custom computation</span>
0477             <span class="comment">%   in a custom calibrate_prediction_function()).</span>
0478             
0479             <span class="comment">% predict given the extracted features and the model</span>
0480             features = self.feature_extract(signal, featuremodel);
0481             features = self.feature_apply_conditioning(features,[],conditioningmodel);
0482             outputs = ml_predict(features, predictivemodel);
0483         <span class="keyword">end</span>
0484         
0485         
0486         <span class="comment">% --- internal implementation ---</span>
0487         
0488         <a name="_sub11" href="#_subfunctions" class="code">function model = calibrate_simple(self,varargin)</a>
0489             <span class="comment">% Calibrates a BCI model based on the given signal and arguments, for later use by the</span>
0490             <span class="comment">% predict_simple function.</span>
0491             <span class="comment">% Model = calibrate_simple(Signal,Arguments...)</span>
0492             <span class="comment">%</span>
0493             <span class="comment">% This function defines the top-level arguments of the paradigm, SignalProcessing</span>
0494             <span class="comment">% (effectively</span>
0495             <span class="comment">%</span>
0496             <span class="comment">% In:</span>
0497             <span class="comment">%   Signal : a single continuous EEGLAB data set (usually annotated with target markers;</span>
0498             <span class="comment">%            see set_targetmarkers for more info)</span>
0499             <span class="comment">%</span>
0500             <span class="comment">%   SignalProcessing : optionally a cell array of custom signal processing parameters,</span>
0501             <span class="comment">%                      as {'filtername',{arguments...}, 'filtername',{arguments..}, ...}</span>
0502             <span class="comment">%                      where the filtername is the name of a flt_*** function or its</span>
0503             <span class="comment">%                      declared CamelCase name (declared by its respective .m file in its</span>
0504             <span class="comment">%                      declare_properties(...) line). CamelCase names are preferred as they</span>
0505             <span class="comment">%                      match the names displayed in the Review/Edit GUI. The arguments is</span>
0506             <span class="comment">%                      a cell array of arguments to the filter, usually name-value pairs.</span>
0507             <span class="comment">%</span>
0508             <span class="comment">%                      Note that these parameters are allowed to override the defaults</span>
0509             <span class="comment">%                      declared by the paradigm in its preprocessing_defaults() function.</span>
0510             <span class="comment">%                      The entire argument list is basically passed to and interpreted by</span>
0511             <span class="comment">%                      flt_pipeline() for execution.</span>
0512             <span class="comment">%</span>
0513             <span class="comment">%   Prediction : optionally a cell array of arguments to calibrate_prediction_function(),</span>
0514             <span class="comment">%                which determines, among others, how feature extraction and/or machine</span>
0515             <span class="comment">%                learning should be performed. This is a cell array of name-value pairs,</span>
0516             <span class="comment">%                and most standard paradigms (which don't override that function) have</span>
0517             <span class="comment">%                here a sub-argument called &quot;FeatureExtraction&quot; (of arguments to feature_adapt())</span>
0518             <span class="comment">%                and one called &quot;MachineLearning&quot; (of arguments to ml_train).</span>
0519             <span class="comment">%</span>
0520             <span class="comment">% Out:</span>
0521             <span class="comment">%   Model : a model struct with a mandatory field .filter_graph and arbitrary other content</span>
0522             <span class="comment">%           * The .filter_graph filed is a 1x1 cell array that contains the desciption of</span>
0523             <span class="comment">%             filter steps that is to be applied to the data, and is usually passed as either</span>
0524             <span class="comment">%             the .tracking.online_expression field of the processed Signal or the processed</span>
0525             <span class="comment">%             Signal itself. If no signal processing is performed by this paradigm, the raw</span>
0526             <span class="comment">%             signal may be passed.</span>
0527             <span class="comment">%</span>
0528             <span class="comment">%           * May have optional fields .prediction_function, .prediction_window and</span>
0529             <span class="comment">%             .prediction_channels - though these are generally auto-deduced</span>
0530             <span class="comment">%</span>
0531             <span class="comment">% Notes:</span>
0532             <span class="comment">%   If you find that you need to override this function (which should be very rare),</span>
0533             <span class="comment">%   it is a better choice to instead inherit directly from ParadigmBaseSimplified.</span>
0534             
0535             args = arg_define(varargin, <span class="keyword">...</span>
0536                 arg_norep({<span class="string">'signal'</span>,<span class="string">'Signal'</span>}), <span class="keyword">...</span>
0537                 arg_sub({<span class="string">'flt'</span>,<span class="string">'SignalProcessing'</span>}, self.preprocessing_defaults(), @flt_pipeline, <span class="string">'Signal processing stages. These parameters control filter stages that run on the signal level; they can be enabled, disabled and configured for the given paradigm. The prediction operates on the outputs of this stage.'</span>), <span class="keyword">...</span>
0538                 arg_sub({<span class="string">'pred'</span>,<span class="string">'Prediction'</span>}, {}, @self.calibrate_prediction_function, <span class="string">'Prediction stage. These parameters control the calibration and processing of stages that run on the output of the signal processing.'</span>), <span class="keyword">...</span>
0539                 arg({<span class="string">'arg_dialogsel'</span>,<span class="string">'ConfigLayout'</span>},self.dialog_layout_defaults(),[],<span class="string">'Parameters displayed in the config dialog. Cell array of parameter names to display (dot-notation allowed); blanks are translated into empty rows in the dialog. Each string refers to an argument (or structure thereof) of the paradigm''s calibrate function. If a structure is identified, all parameters of that struture are listed, except if it is a switchable structure - in this case, a pulldown menu with switch options is displayed.'</span>,<span class="string">'type'</span>,<span class="string">'cellstr'</span>,<span class="string">'shape'</span>,<span class="string">'row'</span>));
0540             
0541             
0542             <span class="comment">% first pre-process the data (symbolically)</span>
0543             <span class="comment">% this means that signal is turned into an unevaluated expression (data structure) like</span>
0544             <span class="comment">% flt_resample(flt_fir(signal,[7,30]), 200)</span>
0545             signal = flt_pipeline(<span class="string">'signal'</span>,args.signal, args.flt); <span class="comment">%#ok&lt;*NODEF&gt;</span>
0546             
0547             <span class="comment">% evaluate this in an optimized fashion (this effectively evaluates the filter expression</span>
0548             <span class="comment">% with some key optimizations, such as caching of intermediate results, turned on)</span>
0549             signal = exp_eval_optimized(signal);
0550             
0551             <span class="comment">% with signal processing done, we now calibrate the prediction function on it, using</span>
0552             <span class="comment">% calibrate_prediction_function(). If the paradigm needs voting, we here call this function</span>
0553             <span class="comment">% on each pair of classes separately.</span>
0554             model.args = rmfield(args,<span class="string">'signal'</span>);
0555             model.classes = unique(set_gettarget(signal),<span class="string">'rows'</span>);
0556             numclasses = size(model.classes,1);
0557             <span class="keyword">if</span> numclasses &gt; 2 &amp;&amp; self.needs_voting()
0558                 <span class="keyword">for</span> i=1:numclasses
0559                     <span class="keyword">for</span> j=i+1:numclasses
0560                         [model.voting{i,j}.featuremodel,model.voting{i,j}.conditioningmodel,model.voting{i,j}.predictivemodel] = self.calibrate_prediction_function(<span class="string">'signal'</span>,exp_eval(set_picktrials(signal,<span class="string">'rank'</span>,{i,j})), args.pred); <span class="keyword">end</span>
0561                 <span class="keyword">end</span>
0562             <span class="keyword">else</span>
0563                 [model.featuremodel,model.conditioningmodel,model.predictivemodel] = self.calibrate_prediction_function(<span class="string">'signal'</span>,signal, args.pred);
0564             <span class="keyword">end</span>
0565             
0566             model.tracking.filter_graph = signal;
0567         <span class="keyword">end</span>
0568         
0569         
0570         <a name="_sub12" href="#_subfunctions" class="code">function outputs = predict_simple(self,signal,model)</a>
0571             <span class="comment">% Override this function to implement your prediction code</span>
0572             <span class="comment">% Outputs = predict_simple(Sginal,Model)</span>
0573             <span class="comment">%</span>
0574             <span class="comment">% In:</span>
0575             <span class="comment">%   Signal : a signal pre-processed according to the model's filter graph</span>
0576             <span class="comment">%</span>
0577             <span class="comment">%   Model : a predictive model as created by your calibrate_simple() function</span>
0578             <span class="comment">%</span>
0579             <span class="comment">% Out:</span>
0580             <span class="comment">%   Outputs : a prediction/estimate for the most recent time point in the data (or one for</span>
0581             <span class="comment">%             every epoch if the signal is epoched); see ml_predict for the allowed formats</span>
0582             <span class="comment">%</span>
0583             <span class="comment">% Notes:</span>
0584             <span class="comment">%   If you find that you need to override this function (which should be very rare),</span>
0585             <span class="comment">%   it is a better choice to instead inherit directly from ParadigmBaseSimplified.</span>
0586             
0587             <span class="keyword">if</span> ~isfield(model,<span class="string">'voting'</span>)
0588                 <span class="comment">% predict given the extracted features and the model</span>
0589                 outputs = self.apply_prediction_function(signal,model.featuremodel,model.conditioningmodel,model.predictivemodel);
0590             <span class="keyword">else</span>
0591                 <span class="comment">% 1-vs-1 voting is necessary, construct the aggregate result</span>
0592                 outputs = [];
0593                 <span class="comment">% vote, adding up the probabilities from each vote</span>
0594                 <span class="keyword">for</span> i=1:length(model.classes)
0595                     <span class="keyword">for</span> j=i+1:length(model.classes)
0596                         outcome = self.apply_prediction_function(signal,model.voting{i,j}.featuremodel,model.voting{i,j}.conditioningmodel,model.voting{i,j}.predictivemodel);
0597                         <span class="keyword">if</span> isempty(outputs)
0598                             outputs = {<span class="string">'disc'</span> , zeros(size(outcome{2},1),length(model.classes)), model.classes}; <span class="keyword">end</span>
0599                         outputs{2}(:,[i j]) = outputs{2}(:,[i j]) + outcome{2};
0600                     <span class="keyword">end</span>
0601                 <span class="keyword">end</span>
0602                 
0603                 <span class="comment">% renormalize probabilities</span>
0604                 outputs{2} = outputs{2} ./ repmat(sum(outputs{2},2),1,size(outputs{2},2));
0605             <span class="keyword">end</span>
0606         <span class="keyword">end</span>
0607         
0608         
0609         <a name="_sub13" href="#_subfunctions" class="code">function visualize(self,model,varargin)</a>
0610             <span class="comment">% Optionally override this function to implement your visualization code</span>
0611             <span class="comment">% visualize(Model)</span>
0612             <span class="comment">%</span>
0613             <span class="comment">% In:</span>
0614             <span class="comment">%   Model: a model as created by your calibrate() function;</span>
0615             <span class="comment">%          a plot or GUI will be produced to inspect the model</span>
0616             
0617             <span class="comment">% visualize the model, either using one figure or multiple in case of voting</span>
0618             <span class="keyword">if</span> ~isfield(model,<span class="string">'voting'</span>)
0619                 p = figure();
0620                 self.visualize_model(p,model.featuremodel,model.predictivemodel,varargin{:});
0621             <span class="keyword">else</span>
0622                 numcl = length(model.classes);
0623                 numclx = length(model.classes)-1;
0624                 <span class="keyword">for</span> i=1:numcl
0625                     <span class="keyword">for</span> j=i+1:numcl
0626                         p = figure(<span class="string">'NumberTitle'</span>,<span class="string">'off'</span>,<span class="string">'MenuBar'</span>,<span class="string">'none'</span>,<span class="string">'Toolbar'</span>,<span class="string">'none'</span>,<span class="string">'Units'</span>,<span class="string">'normalized'</span>, <span class="string">'Name'</span>,sprintf(<span class="string">'%d vs. %d'</span>,i,j), <span class="keyword">...</span>
0627                             <span class="string">'Position'</span>,[(i-0.9)/numclx (j-1-0.9)/numclx 0.8/numclx 0.8/numclx]);
0628                         self.visualize_model(p,model.voting{i,j}.featuremodel,model.voting{i,j}.predictivemodel,varargin{:});
0629                     <span class="keyword">end</span>
0630                 <span class="keyword">end</span>
0631             <span class="keyword">end</span>
0632         <span class="keyword">end</span>
0633         
0634     <span class="keyword">end</span>
0635 <span class="keyword">end</span>
0636 
0637 <span class="comment">% disable a dumb warning about self...</span>
0638 <span class="comment">%#ok&lt;*MANU&gt;</span></pre></div>
<hr><address>Generated on Tue 20-Aug-2013 03:44:10 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>