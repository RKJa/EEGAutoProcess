<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of cov_shrink</title>
  <meta name="keywords" content="cov_shrink">
  <meta name="description" content="Estimate the covariance matrix for some data using analytical shrinkage.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../index.html">Home</a> &gt;  <a href="#">code</a> &gt; <a href="index.html">misc</a> &gt; cov_shrink.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../index.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for code/misc&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>cov_shrink
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>Estimate the covariance matrix for some data using analytical shrinkage.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function [S,lam] = cov_shrink(X,w) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Estimate the covariance matrix for some data using analytical shrinkage.
 Sigma = cov_shrink(X,w)

 This gives robust estimates even when the ratio of number of observations to number of variables is very low. [1]

 X is a matrix where each row is an observation, and each column is a 
 variable. The mean is removed from each column before calculating the
 result. The estimate is unbiased, i.e. cov_shrink normalizes by N-1.

 w is an optional [Nx1] vector of nonnegative weights.

 See also:
   cov, mean

 Dependencies:
   bsxfun

 References:
   [1] J. Schaefer and K. Strimmer,
       &quot;A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics.&quot;
       Statist. Appl. Genet. Mol. Biol. 4:32.

                                Christian Kothe, Swartz Center for Computational Neuroscience, UCSD
                                2010-04-03</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
</ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
</ul>
<!-- crossreference -->



<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [S,lam] = cov_shrink(X,w)</a>
0002 <span class="comment">% Estimate the covariance matrix for some data using analytical shrinkage.</span>
0003 <span class="comment">% Sigma = cov_shrink(X,w)</span>
0004 <span class="comment">%</span>
0005 <span class="comment">% This gives robust estimates even when the ratio of number of observations to number of variables is very low. [1]</span>
0006 <span class="comment">%</span>
0007 <span class="comment">% X is a matrix where each row is an observation, and each column is a</span>
0008 <span class="comment">% variable. The mean is removed from each column before calculating the</span>
0009 <span class="comment">% result. The estimate is unbiased, i.e. cov_shrink normalizes by N-1.</span>
0010 <span class="comment">%</span>
0011 <span class="comment">% w is an optional [Nx1] vector of nonnegative weights.</span>
0012 <span class="comment">%</span>
0013 <span class="comment">% See also:</span>
0014 <span class="comment">%   cov, mean</span>
0015 <span class="comment">%</span>
0016 <span class="comment">% Dependencies:</span>
0017 <span class="comment">%   bsxfun</span>
0018 <span class="comment">%</span>
0019 <span class="comment">% References:</span>
0020 <span class="comment">%   [1] J. Schaefer and K. Strimmer,</span>
0021 <span class="comment">%       &quot;A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics.&quot;</span>
0022 <span class="comment">%       Statist. Appl. Genet. Mol. Biol. 4:32.</span>
0023 <span class="comment">%</span>
0024 <span class="comment">%                                Christian Kothe, Swartz Center for Computational Neuroscience, UCSD</span>
0025 <span class="comment">%                                2010-04-03</span>
0026 
0027 <span class="comment">% Copyright (C) Christian Kothe, SCCN, 2010, christian@sccn.ucsd.edu</span>
0028 <span class="comment">%</span>
0029 <span class="comment">% This program is free software; you can redistribute it and/or modify it under the terms of the GNU</span>
0030 <span class="comment">% General Public License as published by the Free Software Foundation; either version 2 of the</span>
0031 <span class="comment">% License, or (at your option) any later version.</span>
0032 <span class="comment">%</span>
0033 <span class="comment">% This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without</span>
0034 <span class="comment">% even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU</span>
0035 <span class="comment">% General Public License for more details.</span>
0036 <span class="comment">%</span>
0037 <span class="comment">% You should have received a copy of the GNU General Public License along with this program; if not,</span>
0038 <span class="comment">% write to the Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307</span>
0039 <span class="comment">% USA</span>
0040 
0041 mem_quota = 0.2;        <span class="comment">% use at most this fraction of the free memory for temp data</span>
0042 block_increment = 1.5;  <span class="comment">% consider incrementally larger numbers of blocks (incremented by this factor)</span>
0043 
0044 [n,p] = size(X);
0045 <span class="keyword">if</span> nargin &lt; 2
0046     w = 0;
0047 <span class="keyword">else</span>
0048     w = w/sum(w);
0049 <span class="keyword">end</span>
0050 
0051 S = var(X,w);
0052 <span class="keyword">if</span> p ~= 1
0053     scale = diag(sqrt(S));
0054     <span class="comment">% center &amp; standardize</span>
0055     <span class="keyword">if</span> ~isequal(w,0)
0056         X = bsxfun(@minus,X,sum(bsxfun(@times,X,w)));        
0057         X = bsxfun(@times,X,(n-1)./(n*std(X,w)));
0058     <span class="keyword">else</span>
0059         X = bsxfun(@minus,X,sum(X)./n);
0060         X = bsxfun(@times,X,(n-1)./(n*std(X)));
0061     <span class="keyword">end</span>
0062     <span class="comment">% the following computation can be quite memory intensive; do it in successively smaller blocks (if it fails)...</span>
0063     VR = zeros(p);
0064     R = zeros(p);
0065     <span class="comment">% calc candidate data partitionings</span>
0066     tryblocks = ceil(block_increment.^(0:p));
0067     <span class="comment">% calc according temporary data sizes in bytes</span>
0068     trysizes = size(X,1)*(ceil(p./tryblocks)).^2*8;
0069     <span class="comment">% try only those that would fit within the free-memory quota...</span>
0070     <span class="keyword">try</span>
0071         bean = java.lang.management.ManagementFactory.getOperatingSystemMXBean();
0072         mem_free = bean.getFreePhysicalMemorySize();
0073     <span class="keyword">catch</span>
0074         mem_free = 1e10; <span class="comment">% make a fairly conservative assumption</span>
0075     <span class="keyword">end</span>
0076     <span class="keyword">for</span> blocks = tryblocks(trysizes &lt;= mem_free*mem_quota)        
0077         <span class="comment">% 2d block length</span>
0078         blen = ceil(p/blocks);
0079         <span class="comment">% pad X with zeros</span>
0080         X(:,end+1:blen*blocks) = 0;
0081         <span class="keyword">try</span>
0082             <span class="keyword">for</span> bx = 0:blocks-1
0083                 <span class="keyword">for</span> by = 0:blocks-1
0084                     ix = 1+bx*blen : blen+bx*blen;
0085                     iy = 1+by*blen : blen+by*blen;
0086                     <span class="comment">% calc a block of the sample covariance tensor</span>
0087                     B = repmat(reshape(X(:,ix)',[length(ix) 1 n]),[1 length(ix) 1]) .* repmat(reshape(X(:,iy)',[1 length(iy) n]), [length(iy) 1 1]);
0088                     <span class="comment">% calc a block of the per-element weighted variance of the correlation matrix</span>
0089                     VR(ix,iy) = var(B,w,3)*n^2/((n-1)^3);
0090                     <span class="comment">% and calc a block of the mean of the correlation matrix</span>
0091                     <span class="keyword">if</span> ~isequal(w,0)
0092                         R(ix,iy) = sum(bsxfun(@times,permute(w,[3 2 1]),B),3)*n/(n-1);
0093                     <span class="keyword">else</span>
0094                         R(ix,iy) = sum(B,3)/(n-1);
0095                     <span class="keyword">end</span>
0096                 <span class="keyword">end</span>
0097             <span class="keyword">end</span>
0098             <span class="comment">% remove zeros</span>
0099             VR = VR(1:p,1:p);
0100             R = R(1:p,1:p);
0101             <span class="comment">% success...</span>
0102             <span class="keyword">break</span>;
0103          <span class="keyword">catch</span>
0104             <span class="comment">% out of memory, start again</span>
0105          <span class="keyword">end</span>
0106     <span class="keyword">end</span>
0107     <span class="comment">% calc shrinkage parameter</span>
0108     lam = max(0,min(1,sum(sum(tril(VR,-1)))/sum(sum(tril(R,-1).^2))));
0109     <span class="comment">% calc correlation matrix with shrinkage</span>
0110     R = (1-lam)*R;
0111     R(logical(eye(p))) = 1;
0112     <span class="comment">% scale back to covariance matrix</span>
0113     S = scale*R*scale;
0114 <span class="keyword">else</span>
0115     lam = 0;
0116 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Tue 20-Aug-2013 03:44:10 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>