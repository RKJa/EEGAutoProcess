<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of bci_train</title>
  <meta name="keywords" content="bci_train">
  <meta name="description" content="Learn a predictive model given some data and approach, and estimate its performance.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../index.html">Home</a> &gt;  <a href="#">code</a> &gt; <a href="index.html">offline_analysis</a> &gt; bci_train.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../index.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for code/offline_analysis&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>bci_train
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>Learn a predictive model given some data and approach, and estimate its performance.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function [measure,model,stats] = bci_train(varargin) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Learn a predictive model given some data and approach, and estimate its performance.
 [Loss,Model,Statistics] = bci_train(Data, Approach, TargetMarkers, EvaluatationMetric, EvaluationScheme, ...)

 Learns a model of the connection between abstract 'cognitive state' annotations/definitions in a
 data set (e.g., event markers, target variables) and the actual biosignal data, so that the
 learned model can subsequently be used to predict the (defined) cognitive state of the person (in
 real time or offline). Also estimates the quality of the model's predictions, using a measure of
 'mismatch' between what was defined for a given time point and what the model would predict (the
 'loss').


 Model Computation
 =================

 The goal of BCI research is to enable a computer system to read the ongoing EEG (or other
 brain-/biosignals) of a person and predict from it, in real time, what his/her cognitive state is.
 Since the connection between biosignals and cognitive state includes some information that is
 highly specific to a person or group of persons, it can only be obtained from actual data of that
 person (or group), which is here called a 'calibration data set'. For modern expositions of the
 general problem and solutions, see [7] or [8].

 There is currently no general automated method to learn the connection (relation) between a
 calibration data set and the aspect of cognitive state that is to be predicted,  but there is a
 growing body of approaches, here called 'paradigms', each of which imposes a different set of
 assumptions about the nature of that relation. These paradigms tend to perform well if their
 assumptions match the data and if the required information is sufficiently accessible in the
 calibration data set. The result is a 'predictive model' in which the information about the
 connection of interest is captured (usually in some form of statistical mapping).
 
 Almost all paradigms involve some parameters that can be varied to obtain a different variant of
 the paradigm (e.g., the frequency range of interest in the EEG signal), and the better these
 parameters are chosen, the better will be the attainable quality of the models that the paradigm
 can compute. In addition, there is the possibility to search over different values of parameters
 to find a good combination, if allowed by compute/time resources.

 bci_train requires that at least a paradigm is specified (predefined ones are in code/paradigms)
 and that a calibration data set, annotated with expected cognitive state is supplied. Since
 bci_train must learn a relation between raw signal and abstract (human-defined) cognitive state,
 the state must be specified by the user in a machine-accessible format. A typical 'encoding' of
 such state is created as follows. The user records a calibration data set from a person (a regular
 EEG recording). Througout this recording, the person is in different states at different times
 (preferably repeatedly and randomized), for example, instructed to think or feel a sequence of
 specific things (e.g., imagine a left/right hand gesture), or exposed to a series of artificial
 conditions (e.g., high/low excitement), such that the answer to a particular state question is
 known at particular times in the recording (e.g. was a left or right hand gesture being imagined
 at time X?). The times at which there is knowledge about the person's state, and its value at
 these times is encoded into the EEG as 'events', or 'markers'. In EEGLAB data sets, this is the
 field EEG.event, and its type (a string) would be used to encode the state value. Usually, events
 are produced by the software that guides the person though the calibration session and are
 recorded by the data acquisition system. 

 Which events in the data set are relevant and what is the desired output of the BCI for each of 
 these events of interest is specified via the parameter TargetMarkers (or may also be added as an 
 annotation for the data itself, using set_targetmarkers).

 Aside from the chosen paradigm's parameters, this is all there is to specify to bci_train in order
 to obtain a predictive model and its performance estimate. The paradigm's parameters are all
 optional, and are by default set as in the representative (or most commonly) published use of the
 paradigm, so most of them need to be specified only when the user wants to deviate from those
 values.


 Simple Example 
 ==============

 A model that predicts the laterality of imagined hand gestures can be computed as follows
 (assuming that the data set contains events with types 'left-imag' and 'right-imag', at the time
 points where the subject was instructed to imagine the respective action). Since the relevant
 brain signals (Event-Related Desynchronization, see [1]) are assumed to be oscillatory processes
 that originate in distinct areas of the brain, the CSP (Common Spatial Pattern, see, e.g., [2])
 paradigm is used here unmodified. The approach can be specified as a string (usually the acronym
 for one of the ParadigmXXX.m files in code/paradigms) or as a cell array containing that string 
 followed by optional name-value pairs to override/customize parameters.

   calib = io_loadset('data_sets/john/gestures.eeg')
   [loss,model,stats] = bci_train('Data',calib, 'Approach','CSP', 'TargetMarkers',{'left-imag','right-imag'})

 When the loss is good (low) enough to justify online use, the model would then be loaded by the
 user into BCILAB's online system and would predict, whenever it receives EEG that indicates an
 imagined left hand gesture, the number 1 with high probability (and 2 with low probability), and
 in the case of an imagined right hand gesture, the number 2 with high probability (and 1 with low
 probability). At times where the person being measured imagines neither of the defined gestures,
 the system may produce arbitrary predictions. To handle such cases, a further condition (the
 'rest' condition) can be defined for the model, by inserting 'rest' events into the data set
 whenever the subject was in neither of the two other states. The model could then be trained as

   [loss,model,stats] = bci_train('Data',calib, 'Approach','CSP', 'TargetMarkers',{'left-imag','right-imag','rest'}),

 and would predict 3 with high probability (and 1/2 with low probability) in periods where the
 person being measured is in a resting state (note: the function set_insert_markers can be used to
 insert markers of given types into specific periods of the data). Since CSP is by nature a method
 defined for only two conditions, the framework automatically applies it on every pair of
 conditions, which is called voting (see ml_trainvote). Another way to obtain similar results is by
 using two separate models at the same time, one to detect the type of imagination, and the other
 to detect whether an imagination (defined as a group of multiple event types) or resting is
 happening:

   [lossA,modelA] = bci_train('Data',calib, 'Approach','CSP', 'TargetMarkers',{'left-imag','right-imag'}),
   [lossB,modelB] = bci_train('Data',calib, 'Approach','CSP', 'TargetMarkers',{'rest', {'left-imag','right-imag'}})

 Though, in this case it is up to the application to combine the state probabilities that are
 produced by model B with those produced by model A.

 The majority of approaches override at least one parameter of the paradigm, as for example the
 EpochExtraction parameter of the signal processing chain, which determines the time range of 
 interest relative to the events. Thus, calibration of a BCI model usually proceeds in three steps 
 in BCILAB: 

   calib = io_loadset('data_sets/john/gestures.eeg')
   myapproach = {'CSP', 'SignalProcessing',{'EpochExtraction',[0.5 2.5]}};
   [loss,model,stats] = bci_train('Data',calib, 'Approach',myapproach, 'TargetMarkers',{'left-imag','right-imag'})


 Loss Estimation
 ===============

 The most important question to ask about a predictive model is how well it performs, i.e. how well
 do its outputs match the desired outputs -- and for a complete system that performs actions
 depending on a predictive model, what overall cost is incurred by (potentially sub-optimal)
 behavior of the system. Both cases can be covered by a formal 'loss' metric [3]. Different types
 of systems / types of predictive models require different loss metrics, which can be chosen in the
 EvaluationMetric parameter from a set of pre-defined ones, or supplied as a custom function. An 
 introduction to various predefined loss functions and their uses is given in the help of the 
 function machine_learning/ml_calcloss.

 The loss of a model can be computed in a variety of settings. Most obviously and realistically, a
 model can be run online, and the loss incurred by its predictions can be recorded (for example,
 number of mis-classifications, virtual money lost by a BCI-supported gamer). This, however,
 requires multiple (controlled) runs through an experiment to compare different models and/or
 methods, which is usually prohibitively costly. A more effective approach is to record the online
 EEG/biosignal data and the desired outputs of the system whenever they are known, and then
 estimate the loss of any models &quot;offline&quot; on the data, using the loss metric that best reflects
 the actual loss in the chosen scenario (for example mis-classification rate or ROC area); this
 approach requires just one session, and can be used to compare arbitrarily many models post-hoc
 (using the function bci_predict). The caveat is that any chaotic dynamics that may unfold between
 a system mis-behaving and a user reacting are not covered by the estimate (for example, when a
 system fails for more than a minute, the user may start to control it more aggressively, which may
 in turn make it even more difficult for the model to interpret brain signals).

 Finally, a loss estimate can be computed directly by bci_train, on the given calibration data,
 using cross-validation (CV) [4]. This is a data resampling procedure in which models are
 repeatedly computed, each time on a different subset of the data (called the training set) and
 compared on another disjoint portion of the data (called the test set) using the defined (i.e.
 desired) outputs, and some user-selected loss measure. In the default CV, the data is partitioned
 into 10 blocks, where for each block, a model is computed on the remaining 9 ones and tested
 against the target values in the current block (called 10-fold blockwise CV). Other variants
 include k-fold randomized CV, where the data trials are randomly shuffled before a regular
 blockwise k-fold CV, n times repeated k-fold CV, in which n repeated runs over different
 shufflings are executed and results averaged, and leave-one-out CV (LOOCV), where a model is
 computed on all except for one trial, and is then tested on the held-out trial. The loss measure
 is by default chosen depending on the type of target values in the calibration set and the
 features of the paradigm so that the user rarely needs to override it (misclassification rate for
 categorical outputs, mean-square error for continuous outputs, negative log-likelihood for
 probabilistic regression models, etc.).

 The loss estimates of bci_train are very convenient and can be used to evaluate a large variety of
 models on data from a single calibration session. The caveat is that that the estimate
 systematically fails to cover certain features of actual online situations. First, chaotic
 dynamics are not captured, as in the other offline case, and second, only a certain fraction of
 the (time-varying) non-stationarities in the data are captured by the estimate. Most biosignals
 contain features that vary at certain time scales, from second to second (e.g., dopamine level),
 minute to minute (e.g., background situation), hour to hour (e.g., tiredness), day to day (e.g.,
 medication) and year to year (e.g., long-term brain plasticity), all of which can affect the
 output (quality) of the model. Since calibration sessions are usually short, training/test data is
 close to each other in time, and the situation typically has little variation (e.g. it may be all
 offline with no user control involved), the majority of non-stationarities that could degrade the
 model's performance are not captured, and the estimate is almost surely overly optimistic. How
 large this effect is depends among others on the stability of the features used by the model, the
 strength of assumptions imposed by the paradigm, and the variety/coverage of situations present in
 the calibration data.


 Paradigm Customization and Structure
 ====================================

 In the Approach declaration, a list of name-value pairs can be specified, for example 
 {'CSP', 'Resampling',200, 'SpectralSelection',[7 30], 'EpochExtraction',[-1.5 2.5]}, to override the 
 default values of the chosen paradigm for the given named parameters - practically all paradigms have
 named parameters (although some community-supplied ones may have position-dependent parameters -
 like most MATLAB functions). All parameters are basically passed through unmodified to the
 paradigm in question (usually one of the paradigms/ParadigmXXX classes), so the place to
 look up what can be specified is the help of the respective class, or by bringing up the GUI config 
 dialog for the given approach (see GUI tutorial).

 Most paradigms contain similar internal structure, and therefore share common components, which in
 turn means that most of them share multiple common parameters. It is therefore helpful to know
 these components. The internal structure of most paradigms contains a sequence of three overall
 data processing stages. The first stage, Signal Processing, receives (multi-channel) signals, such
 as EEG, and filters these signals to amplify and focus the information of interest, and to discard
 the remaining information. The outputs of the first stage are again signals, either continuous or
 epoched/segmented. The stage may have several successive sub-steps (most of them called filters,
 some called data set editing operations), such as resampling, frequency filtering, spatial
 filtering, time window selection, artifact removal, etc.. The toolbox offers a collection of
 pre-defined filter components (in filters/flt_*) and data set operations (in dataset_ops/set_*),
 each with their respective default parameters. Most paradigms use at least one or two of these
 components, usually with custom parameters for them, and the user can override these parameters by
 specifying the component name (e.g. 'resample' to control the settings of the used sampling rate
 filter, flt_resample) followed by the parameter value to be passed (e.g. 200 for 200 Hz in the
 case of flt_resample), or a cell array of parameters if the component accepts multiple parameters,
 such as flt_ica does. Furthermore, most paradigms not only use a subset of the provided filters,
 but instead use the entire default Signal Processing pipeline of the toolbox, explained in
 filters/flt_pipeline. For this reason, all parameters of flt_pipeline can be customized by the
 user for almost any paradigm (and not just those chosen by the paradigm), i.e. the user can enable 
 and configure stages in the default pipeline which are normally disabled in the given paradigm. Note
 that flt_pipeline offers a few alias names for some parameters, e.g. 'channels' can be used
 instead of 'selchans', both controlling filters/flt_selchans; these are listed in flt_pipeline.

 The second stage of most paradigms is the Feature Extraction stage, which receives the
 preprocessed signals from the Signal Processing, and extracts certain informative features (e.g.
 logarithm of the signal power). This stage is usually custom to the paradigm, and is therefore
 controlled by unique parameters (e.g. 'patterns' in the Common Spatial Patterns [2] paradigm,
 para_csp).

 Finally, the feature produced by the Feature Extraction are usually subjected to a last stage, the
 Machine Learning. In this, a learning component, which is one of the provided
 machine_learning/ml_train* functions, computes a statistical model of the feature distributions,
 and their relation to the desired output values. This component is generally selected via the
 'learner' parameter, which is exposed by most paradigms. The learner can be specified as name tag, 
 such as 'lda', which refers to ml_trainlda. If the learner component contains parameters which shall 
 be costomized as well, a cell array is passed which contains the name tag followed by the custom 
 parameters, in the order of appearance in the respective learning function. For example, 
 'learner',{'svmlinear',0.5} selects The linear SVM component and sets its Cost parameter to 0.5, 
 and 'learner',{'logreg',[],'variant','vb-ard'} selects the Logistic Regression component, keeps its 
 first parameter at the default value, and uses the custom variant 'vb-ard', which stands for 
 Variational Bayes with Automatic Relevance Determination (see, e.g., [7]). A small but useful subset 
 of the provided Signal Processing, Feature Extraction and Machine Learning components is compactly 
 described in [5].


 Customized Example
 ==================

 To obtain an online prediction of the working-memory load of a person, a calibration data set in
 which the person has to maintain varying numbers of items is his/her memory (e.g., using the
 n-back task, see [6]) can be used as a starting point. In this data set, conditions with one item
 in memory are marked with the event 'n1', conditions with two items in memory are marked with
 'n2', etc. Assuming that working-memory load may be reflected in certain oscillatory processes,
 though in unknown locations and frequency bands, the paradigm Spec-CSP ([9]) is used as a basis.
 In its default configuration (see paradigms/ParadigmSpecCSP), it focuses on a relatively narrow
 frequency band, which shall be relaxed here (in particular, the theta band [10] should be
 included). Also, by default, the Spec-CSP paradigm selects data epochs at 0.5-3.5 seconds
 following each (selected) event, which shall be modified to [-2.5 2.5], to get a time coverage
 that is better adapted to the task. Finally, Spec-CSP by default contains a non-probabilistic
 classifier (Linear Discriminant Analysis, see machine_learning/ml_trainlda), which we want to
 change into a largely equivalent, but probabilistic one (Logistic regression, see
 machine_learning/ml_trainlogreg). Since we assume that the most important part of the spectrum
 will be the alpha and theta rhythm (peaked at ~10 and ~4Hz), but do not want to completely rule
 out other frequencies, we additionally impose a prior as a custom in-line (lambda) function of
 frequency). Since we have more than two classes, but the Spec-CSP is only defined for two classes,
 the framework automatically applies it to every pair of conditions and uses voting (see
 machine_learning/ml_trainvote) to arrive at per-class probabilities. Note that this is a major
 customization.

   dataset = io_loadset('data sets/mary/nback.eeg')
   myapproach = {'SpecCSP', ...
       'SignalProcessing',{'EpochExtraction',[-2.5 2.5], 'FIRFilter',{'Frequencies',[2 4 33 34],'Type','minimum-phase'}}, ...
       'Prediction',{'FeatureExtraction',{'SpectralPrior','@(f)1+exp(-(x-10).^2)+exp(-(x-4).^2'}, ...
                     'MachineLearning',{'Learner','logreg'}}};
   [loss,model,stats] = bci_train('Data',dataset, 'Approach',myapproach, 'TargetMarkers',{'n1','n2','n3'})

 This model will predict either 1,2, or 3 with high confidence, when the user is maintaining the
 respective number of items in his/her working memory, but will likely be fairly specific to the
 task on which it was calibrated.


 Parameter searching
 ===================
 
 In some cases, the optimal setting of certain parameters of a paradigm might not be known, but may
 drastically affect the performance of the method. One example are the time boundaries w.r.t. to
 the supplied events, which may depend on the reaction time of the user, among other things.
 Another example are regularization parameters which are used to constrain the complexity of the
 learned model (see, e.g. [11]). Regularization is a very powerful concept which enables methods
 such as Support Vector Machines and LASSO, in which the parameter is neither designed to be
 manually selected nor is it very interpretable in terms of brain processes. But most importantly,
 manual selection of these parameters (by trial and error) invalidates the performance guarantees
 that are made by the loss estimates: the performance estimate found for the hand-selected model is
 likely far better than the actual performance of that model. This is because the influence of
 random fluctuations in the estimate over the possible parameters is maximized by the user when
 he/she accepts the best one as the actual performance of the method (similar in spirit to the
 fallacy of multiple hypothesis tests without correction).

 For these reasons, bci_train offers a generic mechanism to search over parameters (or parameter
 combinations), in user-defined intervals and granularity, and uses a nested cross-validation
 method to give unbiased loss estimates. In this method, the search for the best parameter (using
 cross-validation derived estimates) is done inside an outer cross-validation, in each of its
 steps, and is restricted to the respective training set of that step. This way, the performance of
 the search procedure itself can be objectively evaluated on held-out test data. The
 cross-validation scheme for this inner search procedure can be specified via the OptimizationScheme
 parameter (part of the Training-Options), which has the same format as the EvaluationScheme
 parameter. By default, it is set to a 5-fold blockwise cross-validation with 5 trials safety
 margin. As a downside, parameter search multiplies the time it takes to compute a model by a
 potentially large factor; the total computation time of bci_train is (# of folds in the outer
 cross-validation) * (# of folds in the inner cross-validation) * (# of parameter combinations) *
 (time to compute a single model). Thus, the evaluation (outer) cross-validation may in some cases
 be turned off ('eval_scheme' set to 0) to obtain a model in a reasonable time, e.g., between a
 calibration session and a subsequent online session.

 Any value supplied to the paradigm can be replaced by a search range, written as search(...), to
 indicate to bci_train that this parameter is subject to a search. The search() clause can be used
 in any place of the data passed to the paradigm (e.g. inside cell arrays and/or structs), and can
 run over any data type supported by MATLAB, such as numbers, strings, structs, and vectors.


 Parameter Search Examples
 =========================

 In the case of imagined hand gestures (see first example), the time period in which the user
 performs the imaginations may not be known in advance (e.g. one user may imagine to clench the
 fist, while another user may imagine a whole sequence of finger movements). Therefore, the exact
 boundaries of the relevant data are not known, and can be searched (or spectral heuristics could
 be used). We assume that the response time of the user following the instruction may vary between
 0.25 seconds and 0.75 seconds, and we choose to search over the range at a granualarity of 0.1
 seconds. The time it takes until the imagination is finished may vary between 1.5 seconds and 4.5
 seconds, and we search over values at a granularity of 0.5 seconds. Thus, para_csp's default
 'epoch' parameter [0.5,3.5] is replaced by [search(0.25:0.1:0.75), search(1.5:0.5:4.5)]:

   calib = io_loadset('data sets/john/gestures.eeg')
   myapproach = {'CSP' 'SignalProcessing',{'EpochExtraction',[search(0.25:0.1:0.75),search(1.5:0.5:4.5)]}};
   [loss,model,stats] = bci_train('Data',calib, 'Approach',myapproach}, 'TargetMarkers',{'left-imag','right-imag'})

 Since the search runs over 6*7 parameters, and a 5x inner cross-validation is performed, the
 overall running time will be 6*7*5 = 210x the default running time. If such a procedure shall be
 run immediately prior to an online session, it is better to disable the outer cross-validation
 altogether, which brings the time down to 21x of the default.


 As a second example, suppose that the goal is to predict whether the user perceives some event as
 being erroneous or not. A possible calibration data set could contain events of two classes, 'err'
 and 'cor', which encode time points where the user encountered errorneous and correct events. The
 assumption is that the user's event processing is accompanied by a characteristic slow cortical
 potential [12] which allows to discern between the two conditions. As a paradigm, we use the
 ERP version of the Dual-Agumented Lagrange method [13], which makes few assumptions
 except that the cognitive process of interest is simple enough in its time/space behavior to be
 tractably recognized. We restrict the analysis to the period of -0.2 to 0.65s around the event,
 resample to 60Hz, filter to ~0.3-19Hz, and specify a custom parameter search range for the DAL machine
 learning function. The complexity of the learned model is controlled via a regularization
 parameter, called Lambda. This parameter is the first user-accessible parameter in the learning
 function ml_traindal (its first two parameters are implicitly specified by the framework and
 contain the actual data; this contract holds for all other learning functions
 machine_learning/ml_train*, as well). Instead of specifying an ad hoc value here, we instead
 let bci_train search over a large feasible interval.

   calib = io_loadset('data sets/john/errorperception.eeg')
   myapproach = {'DALERP', ...
       'SignalProcessing',{'EpochExtraction',[-0.2 0.65]}, ...
       'Prediction',{'MachineLearning',{'Learner',{'dal',search(2.^(8:-0.125:1))}}}};
   [loss,model,stats] = bci_train('Data',calib,'Approach',myapproach, 'TargetMarkers',{'err','cor'})

 This example is for illustrative purposes because the ml_traindal has its own highly optimized 
 parameter search code, which would kick in if the first parameter was specified as an array of 
 possible values (i.e. without the search() clause).

 Statistics
 ==========
 
 Aside from an average loss measure, a structure of additional statistics can be obtained from
 bci_train via its third output parameter, Statistics. The most relevant part of the statistics are
 the per-fold loss measures (computed in each cross-validation fold), which can be used to run
 statistical tests on the significance of outcomes, etc.; these are in the struct array .per_fold.
 This also includes the target values (.targ) and predicted values (.pred) for the trials in each
 fold, as well as the indices of the fold's trials in the full original data set (.indices).
 Depending on the type of loss measure, additional values may be available per fold (e.g. fraction
 of true and false positives, etc).

 If the model was obtained in a parameter search, the field .modelsearch contains the complete set of
 loss measures and computed models for each tested parameter combination (on the entire calibration
 set), which includes, among others, the regularization path for regularized classifiers, which
 allows for very detailed analyses of the computed models.

 Additional fields include, depending on the type of target variables, .classes and .class_ratio
 contain the possible output values of the model (e.g. [1,2,3,4,5] in a  standard 5-class
 classification task) as well as the fraction of data trials belonging to each class. The field
 .model contains the computed model, the field .expression contains an expression data structure
 which summarizes the parameters that went into the comptuation of the result(s), including those
 that determined the data set(s) used for calibration. The function hlp_tostring can format it into
 a human-readable string.


 Model Usage
 ===========

 The computed model can subsequently be used with other parts of the toolbox. Most importantly, the
 model can be used with the online system of the toolbox, either via one of the provided online
 plugins or directly through BCILAB's online application programming interface (API), explained in
 online_analysis/onl_*. Aside from online analysis, the model can be used for offline analysis of
 data sets, via the functions bci_predict (make predictions for every trial in a given data set),
 onl_stream (make predictions for desired time points in a given data set), and bci_preproc
 (preprocess a given data set into its pre-feature extraction form for analysis and visualization
 with EEGLAB tools). Finally, model properties can be visualized and inspected using visualization
 methods (visualizations/vis_*). The model can be saved to disk and re-loaded later.


 In:
    --- core arguments ---

    Data : Data set. EEGLAB data set, or stream bundle, or cell array of data sets / stream bundles
           to use for calibration/evaluation.

    Approach : Computational approach. Specification of a computational approach (usually a cell 
               array, alternatively a struct). If a cell array, the first cell is the name of the 
               paradigm (usually just the acronym of an existing ParadigmXXX class), and the rest are
               name-value pairs specifying optional custom arguments for the paradigm.

   TargetMarkers : Target markers. List of types of those markers around which data shall be used
                   for BCI calibration; each marker type encodes a different target class (i.e.
                   desired output value) to be learned by the resulting BCI model. 
                   
                   This can be specified either as a cell array of marker-value pairs, in which
                   case each marker type of BCI interest is associated with a particular BCI output 
                   value (e.g., -1/+1), or as a cell array of marker types (in which case each 
                   marker will be associated with its respective index as corresponding BCI output 
                   value, while nested cell arrays are also allowed to group markers that correspond
                   to the same output value). See help of set_targetmarkers for further explanation.


   --- miscellaneous arguments ---

   EventField : Event field to search for target markers, provided as a string. If not provided,
                the field 'type' will be used by default.

   EvaluationMetric : Evaluation metric. The metric to use in the assessment of model performance
                      (via cross-validation). Can be empty, a string, or a function handle.
                      See ml_calcloss() for the options (default: [] = auto-select between 
                      kullback-leibler divergence ('kld'), mean square error ('mse'), mis-classification 
                      rate ('mcr') and negative log-likelihood ('nll') depending on the type of the 
                      target and prediction variables, further detailed in ml_calcloss())

   EvaluationScheme : Evaluation scheme. Cross-validation scheme to use for evaluation. See 
                      utl_crossval for the default settings when operating on a single recording
                      (there it is called 'scheme'), and utl_collection_partition when operating on
                      a collection of data sets. In the case of single data sets, a reasonable
                      choice for final results is {'chron',10,5} which stands for 10-fold
                      chronological/blockwise cross-validation with 5 trials margin between
                      training and test sets. Default: {'chron',5,5}, which is twice as fast, for
                      more rapid workflow. A standard choice in machine learning is 10-fold randomized
                      cross-validation, which you get by setting this parameter to 10 (though it is
                      not ideal for time-series data).

   OptimizationScheme : Optimization scheme. Cross-validation scheme to use for parameter search 
                        (this is a nested cross-validation, only performed if there are parameters
                        to search). The format is the same as in EvaluationScheme; default is
                        {'chron',5,5}, which is a reasonable choice for final results.
   
   GoalIdentifier : Goal identifier. This is only used for training on multiple recordings and
                    serves to identify the data set on which the BCI shall eventually be used
                    (e.g., the Subject Id, Day, etc. of the goal data set).

   EpochBounds : Epoch bounds override. Tight upper bound of epoch windows used for epoching (by
                 default [-5 5]). This is only used if the cross-validation needs to run on
                 continuous data because a continuous-data statistic needs to be computed over the
                 training set (such as ICA).

   CrossvalidationResources : Cross-validation parallelization. Same meaning and options as the
                              ParameterSearchEngine parameter, however for the cross-validations.
                              By default set to 'global'.

   ParameterSearchResources : Parameter search parallelization. If set to 'global', the global BCILAB
                              setting will be used to determine when to run this computation. If set
                              to 'local', the computation will be done on the local machine.
                              Otherwise,the respective scheduler will be used to distribute the
                              computation across a cluster (default: 'local')
   
   NestedCrossvalResources : Nested cross-validation parallelization. If set to 'global', the
                             global BCILAB setting will be used to determine when to run this
                             computation. If set to 'local', the computation will be done on the
                             local machine. Otherwise,the respective scheduler will be used to
                             distribute the computation across a cluster (default: 'local')

   ResourcePool : Parallel compute resouces. If set to ''global'', the globally set BCILAB resource 
                  pool will be used, otherwise this should be a cell array of 'hostname:port'
                  strings (default: 'global')

 Out:
   Loss       : a measure of the overall performance of the paradigm combination, w.r.t. to the 
                target variable returned by gettarget, computed by the specified loss metric.

   Model      : a predictive model (&quot;detector&quot;), as computed by the specified paradigm; can be 
                loaded into the online system via onl_loaddetector, applied offline to new data via
                bci_predict, and analyzed using various visualizers

   Statistics : additional statistics, as produced by the specified metric; if the model itself is 
                determined via parameter search, further statistics from the model searching are in
                the subfield stats.model

 Examples:
   % assuming that a data set has been loaded, and a computational approach has been defined 
   % similarly to the following code:
   traindata = io_loadset('bcilab:/userdata/tutorial/imag_movements1/calib/DanielS001R01.dat');
   myapproach = {'CSP' 'SignalProcessing',{'EpochExtraction',[0 3.5]}};

   % learn a model and get the mis-classification rate, as well as statistics
   [trainloss,lastmodel,laststats] = bci_train('Data',traindata,'Approach',myapproach,'TargetMarkers',{'StimulusCode_2','StimulusCode_3'});

   % as before, but use a coarser block-wise (chronological) cross-validation (5-fold, with 3 trials margin)
   [trainloss,lastmodel,laststats] = bci_train('Data',traindata,'Approach',myapproach,'EvaluationScheme',{'chron',5,3}'TargetMarkers',{'StimulusCode_2','StimulusCode_3'});

   % as before, but use a 10-fold randomized cross-validation (rarely recommended)
   [trainloss,lastmodel,laststats] = bci_train('Data',traindata,'Approach',myapproach,'EvaluationScheme',10,'TargetMarkers',{'StimulusCode_2','StimulusCode_3'});

   % as before, using a 10-fold, 10x repeated randomized cross-validation
   [trainloss,lastmodel,laststats] = bci_train('Data',traindata,'Approach',myapproach,'EvaluationScheme',[10 10],'TargetMarkers',{'StimulusCode_2','StimulusCode_3'});

   % using a different loss measure (here: mean-square error, instead of the default mis-classification rate)
   [trainloss,lastmodel,laststats] = bci_train('Data',traindata,'Approach',myapproach,'EvaluationMetric','mse','TargetMarkers',{'StimulusCode_2','StimulusCode_3'});


 References:
   [1] Pfurtscheller, G., and da Silva, L. &quot;Event-related EEG/MEG synchronization and desynchronization: basic principles.&quot;
       Clin Neurophysiol 110, 1842-1857, 1999
   [2] Ramoser, H., Mueller-Gerking, J., Pfurtscheller G. &quot;Optimal spatial filtering of single trial EEG during imagined hand movement.&quot; 
       IEEE Trans Rehabil Eng. Dec 8 (4): 441-6, 2000
   [3] MacKay, D. J. C. &quot;Information theory, inference, and learning algorithms.&quot; 
       Cambridge University Press, 2003.
   [4] Duda, R., Hart, P., and Stork, D., &quot;Pattern Classification.&quot;, Second Ed.
       John Wiley &amp; Sons, 2001.
   [5] Dornhege, G. &quot;Increasing Information Transfer Rates for Brain-Computer Interfacing.&quot;
       Ph.D Thesis, University of Potsdam, 2006.
   [6] Owen, A. M., McMillan, K. M., Laird, A. R. &amp; Bullmore, E. &quot;N-back working memory paradigm: A meta-analysis of normative functional neuroimaging studies.&quot;
       Human Brain Mapping, 25, 46-59, 2005
   [7] Bishop, C. M. &quot;Pattern Recognition and Machine Learning.&quot; 
       Information Science and Statistics. Springer, 2006.
   [8] Hastie, T., Tibshirani, R., and Friedman, J. H. &quot;The elements of statistical learning (2nd Ed.).&quot; 
        Springer, 2009.
   [9] Tomioka, R., Dornhege, G., Aihara, K., and Mueller, K.-R.. &quot;An iterative algorithm for spatio-temporal filter optimization.&quot; 
       In Proceedings of the 3rd International Brain-Computer Interface Workshop and Training Course 2006, pages 22-23. Verlag der Technischen Universitaet Graz, 2006.
   [10] Buzsaki, G., &quot;Rhythms of the brain&quot;
        Oxford University Press US, 2006
   [11] Tibshirani, R. . &quot;Regression Shrinkage and Selection via the Lasso&quot;
        Journal of the Royal Statistical Society, Series B (Methodology) 58 (1): 267-288, 1996
   [12] Holroyd, C.B., Coles, M.G.. &quot;The neural basis of human error processing: reinforcement learning, dopamine, and the error-related negativity&quot;
        Psychological Review, 109, 679-709, 2002
   [13] Tomioka, R. and Mueller, K.-R. &quot;A regularized discriminative framework for EEG analysis with application to brain-computer interface&quot;
        Neuroimage, 49 (1) pp. 415-432, 2010.
   [14] Onton J &amp; Makeig S. &quot;Broadband high-frequency EEG dynamics during emotion imagination.&quot;
        Frontiers in Human Neuroscience, 2009. 

 See also:
   <a href="bci_predict.html" class="code" title="function [prediction, measure, stats, target] = bci_predict(varargin)">bci_predict</a>, <a href="bci_batchtrain.html" class="code" title="function results = bci_batchtrain(varargin)">bci_batchtrain</a>, <a href="bci_visualize.html" class="code" title="function bci_visualize(model,varargin)">bci_visualize</a>, <a href="bci_annotate.html" class="code" title="function data = bci_annotate(varargin)">bci_annotate</a>, io_loadset,
   onl_simulate, onl_newpredictor, utl_crossval, utl_searchmodel,
   utl_nested_crossval

                               Christian Kothe, Swartz Center for Computational Neuroscience, UCSD
                               2010-04-24</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
</ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
</ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function [measure,model,stats] = run_computation(opts,crossval_args)</a></li><li><a href="#_sub2" class="code">function res = collect_instances(x,field)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [measure,model,stats] = bci_train(varargin)</a>
0002 <span class="comment">% Learn a predictive model given some data and approach, and estimate its performance.</span>
0003 <span class="comment">% [Loss,Model,Statistics] = bci_train(Data, Approach, TargetMarkers, EvaluatationMetric, EvaluationScheme, ...)</span>
0004 <span class="comment">%</span>
0005 <span class="comment">% Learns a model of the connection between abstract 'cognitive state' annotations/definitions in a</span>
0006 <span class="comment">% data set (e.g., event markers, target variables) and the actual biosignal data, so that the</span>
0007 <span class="comment">% learned model can subsequently be used to predict the (defined) cognitive state of the person (in</span>
0008 <span class="comment">% real time or offline). Also estimates the quality of the model's predictions, using a measure of</span>
0009 <span class="comment">% 'mismatch' between what was defined for a given time point and what the model would predict (the</span>
0010 <span class="comment">% 'loss').</span>
0011 <span class="comment">%</span>
0012 <span class="comment">%</span>
0013 <span class="comment">% Model Computation</span>
0014 <span class="comment">% =================</span>
0015 <span class="comment">%</span>
0016 <span class="comment">% The goal of BCI research is to enable a computer system to read the ongoing EEG (or other</span>
0017 <span class="comment">% brain-/biosignals) of a person and predict from it, in real time, what his/her cognitive state is.</span>
0018 <span class="comment">% Since the connection between biosignals and cognitive state includes some information that is</span>
0019 <span class="comment">% highly specific to a person or group of persons, it can only be obtained from actual data of that</span>
0020 <span class="comment">% person (or group), which is here called a 'calibration data set'. For modern expositions of the</span>
0021 <span class="comment">% general problem and solutions, see [7] or [8].</span>
0022 <span class="comment">%</span>
0023 <span class="comment">% There is currently no general automated method to learn the connection (relation) between a</span>
0024 <span class="comment">% calibration data set and the aspect of cognitive state that is to be predicted,  but there is a</span>
0025 <span class="comment">% growing body of approaches, here called 'paradigms', each of which imposes a different set of</span>
0026 <span class="comment">% assumptions about the nature of that relation. These paradigms tend to perform well if their</span>
0027 <span class="comment">% assumptions match the data and if the required information is sufficiently accessible in the</span>
0028 <span class="comment">% calibration data set. The result is a 'predictive model' in which the information about the</span>
0029 <span class="comment">% connection of interest is captured (usually in some form of statistical mapping).</span>
0030 <span class="comment">%</span>
0031 <span class="comment">% Almost all paradigms involve some parameters that can be varied to obtain a different variant of</span>
0032 <span class="comment">% the paradigm (e.g., the frequency range of interest in the EEG signal), and the better these</span>
0033 <span class="comment">% parameters are chosen, the better will be the attainable quality of the models that the paradigm</span>
0034 <span class="comment">% can compute. In addition, there is the possibility to search over different values of parameters</span>
0035 <span class="comment">% to find a good combination, if allowed by compute/time resources.</span>
0036 <span class="comment">%</span>
0037 <span class="comment">% bci_train requires that at least a paradigm is specified (predefined ones are in code/paradigms)</span>
0038 <span class="comment">% and that a calibration data set, annotated with expected cognitive state is supplied. Since</span>
0039 <span class="comment">% bci_train must learn a relation between raw signal and abstract (human-defined) cognitive state,</span>
0040 <span class="comment">% the state must be specified by the user in a machine-accessible format. A typical 'encoding' of</span>
0041 <span class="comment">% such state is created as follows. The user records a calibration data set from a person (a regular</span>
0042 <span class="comment">% EEG recording). Througout this recording, the person is in different states at different times</span>
0043 <span class="comment">% (preferably repeatedly and randomized), for example, instructed to think or feel a sequence of</span>
0044 <span class="comment">% specific things (e.g., imagine a left/right hand gesture), or exposed to a series of artificial</span>
0045 <span class="comment">% conditions (e.g., high/low excitement), such that the answer to a particular state question is</span>
0046 <span class="comment">% known at particular times in the recording (e.g. was a left or right hand gesture being imagined</span>
0047 <span class="comment">% at time X?). The times at which there is knowledge about the person's state, and its value at</span>
0048 <span class="comment">% these times is encoded into the EEG as 'events', or 'markers'. In EEGLAB data sets, this is the</span>
0049 <span class="comment">% field EEG.event, and its type (a string) would be used to encode the state value. Usually, events</span>
0050 <span class="comment">% are produced by the software that guides the person though the calibration session and are</span>
0051 <span class="comment">% recorded by the data acquisition system.</span>
0052 <span class="comment">%</span>
0053 <span class="comment">% Which events in the data set are relevant and what is the desired output of the BCI for each of</span>
0054 <span class="comment">% these events of interest is specified via the parameter TargetMarkers (or may also be added as an</span>
0055 <span class="comment">% annotation for the data itself, using set_targetmarkers).</span>
0056 <span class="comment">%</span>
0057 <span class="comment">% Aside from the chosen paradigm's parameters, this is all there is to specify to bci_train in order</span>
0058 <span class="comment">% to obtain a predictive model and its performance estimate. The paradigm's parameters are all</span>
0059 <span class="comment">% optional, and are by default set as in the representative (or most commonly) published use of the</span>
0060 <span class="comment">% paradigm, so most of them need to be specified only when the user wants to deviate from those</span>
0061 <span class="comment">% values.</span>
0062 <span class="comment">%</span>
0063 <span class="comment">%</span>
0064 <span class="comment">% Simple Example</span>
0065 <span class="comment">% ==============</span>
0066 <span class="comment">%</span>
0067 <span class="comment">% A model that predicts the laterality of imagined hand gestures can be computed as follows</span>
0068 <span class="comment">% (assuming that the data set contains events with types 'left-imag' and 'right-imag', at the time</span>
0069 <span class="comment">% points where the subject was instructed to imagine the respective action). Since the relevant</span>
0070 <span class="comment">% brain signals (Event-Related Desynchronization, see [1]) are assumed to be oscillatory processes</span>
0071 <span class="comment">% that originate in distinct areas of the brain, the CSP (Common Spatial Pattern, see, e.g., [2])</span>
0072 <span class="comment">% paradigm is used here unmodified. The approach can be specified as a string (usually the acronym</span>
0073 <span class="comment">% for one of the ParadigmXXX.m files in code/paradigms) or as a cell array containing that string</span>
0074 <span class="comment">% followed by optional name-value pairs to override/customize parameters.</span>
0075 <span class="comment">%</span>
0076 <span class="comment">%   calib = io_loadset('data_sets/john/gestures.eeg')</span>
0077 <span class="comment">%   [loss,model,stats] = bci_train('Data',calib, 'Approach','CSP', 'TargetMarkers',{'left-imag','right-imag'})</span>
0078 <span class="comment">%</span>
0079 <span class="comment">% When the loss is good (low) enough to justify online use, the model would then be loaded by the</span>
0080 <span class="comment">% user into BCILAB's online system and would predict, whenever it receives EEG that indicates an</span>
0081 <span class="comment">% imagined left hand gesture, the number 1 with high probability (and 2 with low probability), and</span>
0082 <span class="comment">% in the case of an imagined right hand gesture, the number 2 with high probability (and 1 with low</span>
0083 <span class="comment">% probability). At times where the person being measured imagines neither of the defined gestures,</span>
0084 <span class="comment">% the system may produce arbitrary predictions. To handle such cases, a further condition (the</span>
0085 <span class="comment">% 'rest' condition) can be defined for the model, by inserting 'rest' events into the data set</span>
0086 <span class="comment">% whenever the subject was in neither of the two other states. The model could then be trained as</span>
0087 <span class="comment">%</span>
0088 <span class="comment">%   [loss,model,stats] = bci_train('Data',calib, 'Approach','CSP', 'TargetMarkers',{'left-imag','right-imag','rest'}),</span>
0089 <span class="comment">%</span>
0090 <span class="comment">% and would predict 3 with high probability (and 1/2 with low probability) in periods where the</span>
0091 <span class="comment">% person being measured is in a resting state (note: the function set_insert_markers can be used to</span>
0092 <span class="comment">% insert markers of given types into specific periods of the data). Since CSP is by nature a method</span>
0093 <span class="comment">% defined for only two conditions, the framework automatically applies it on every pair of</span>
0094 <span class="comment">% conditions, which is called voting (see ml_trainvote). Another way to obtain similar results is by</span>
0095 <span class="comment">% using two separate models at the same time, one to detect the type of imagination, and the other</span>
0096 <span class="comment">% to detect whether an imagination (defined as a group of multiple event types) or resting is</span>
0097 <span class="comment">% happening:</span>
0098 <span class="comment">%</span>
0099 <span class="comment">%   [lossA,modelA] = bci_train('Data',calib, 'Approach','CSP', 'TargetMarkers',{'left-imag','right-imag'}),</span>
0100 <span class="comment">%   [lossB,modelB] = bci_train('Data',calib, 'Approach','CSP', 'TargetMarkers',{'rest', {'left-imag','right-imag'}})</span>
0101 <span class="comment">%</span>
0102 <span class="comment">% Though, in this case it is up to the application to combine the state probabilities that are</span>
0103 <span class="comment">% produced by model B with those produced by model A.</span>
0104 <span class="comment">%</span>
0105 <span class="comment">% The majority of approaches override at least one parameter of the paradigm, as for example the</span>
0106 <span class="comment">% EpochExtraction parameter of the signal processing chain, which determines the time range of</span>
0107 <span class="comment">% interest relative to the events. Thus, calibration of a BCI model usually proceeds in three steps</span>
0108 <span class="comment">% in BCILAB:</span>
0109 <span class="comment">%</span>
0110 <span class="comment">%   calib = io_loadset('data_sets/john/gestures.eeg')</span>
0111 <span class="comment">%   myapproach = {'CSP', 'SignalProcessing',{'EpochExtraction',[0.5 2.5]}};</span>
0112 <span class="comment">%   [loss,model,stats] = bci_train('Data',calib, 'Approach',myapproach, 'TargetMarkers',{'left-imag','right-imag'})</span>
0113 <span class="comment">%</span>
0114 <span class="comment">%</span>
0115 <span class="comment">% Loss Estimation</span>
0116 <span class="comment">% ===============</span>
0117 <span class="comment">%</span>
0118 <span class="comment">% The most important question to ask about a predictive model is how well it performs, i.e. how well</span>
0119 <span class="comment">% do its outputs match the desired outputs -- and for a complete system that performs actions</span>
0120 <span class="comment">% depending on a predictive model, what overall cost is incurred by (potentially sub-optimal)</span>
0121 <span class="comment">% behavior of the system. Both cases can be covered by a formal 'loss' metric [3]. Different types</span>
0122 <span class="comment">% of systems / types of predictive models require different loss metrics, which can be chosen in the</span>
0123 <span class="comment">% EvaluationMetric parameter from a set of pre-defined ones, or supplied as a custom function. An</span>
0124 <span class="comment">% introduction to various predefined loss functions and their uses is given in the help of the</span>
0125 <span class="comment">% function machine_learning/ml_calcloss.</span>
0126 <span class="comment">%</span>
0127 <span class="comment">% The loss of a model can be computed in a variety of settings. Most obviously and realistically, a</span>
0128 <span class="comment">% model can be run online, and the loss incurred by its predictions can be recorded (for example,</span>
0129 <span class="comment">% number of mis-classifications, virtual money lost by a BCI-supported gamer). This, however,</span>
0130 <span class="comment">% requires multiple (controlled) runs through an experiment to compare different models and/or</span>
0131 <span class="comment">% methods, which is usually prohibitively costly. A more effective approach is to record the online</span>
0132 <span class="comment">% EEG/biosignal data and the desired outputs of the system whenever they are known, and then</span>
0133 <span class="comment">% estimate the loss of any models &quot;offline&quot; on the data, using the loss metric that best reflects</span>
0134 <span class="comment">% the actual loss in the chosen scenario (for example mis-classification rate or ROC area); this</span>
0135 <span class="comment">% approach requires just one session, and can be used to compare arbitrarily many models post-hoc</span>
0136 <span class="comment">% (using the function bci_predict). The caveat is that any chaotic dynamics that may unfold between</span>
0137 <span class="comment">% a system mis-behaving and a user reacting are not covered by the estimate (for example, when a</span>
0138 <span class="comment">% system fails for more than a minute, the user may start to control it more aggressively, which may</span>
0139 <span class="comment">% in turn make it even more difficult for the model to interpret brain signals).</span>
0140 <span class="comment">%</span>
0141 <span class="comment">% Finally, a loss estimate can be computed directly by bci_train, on the given calibration data,</span>
0142 <span class="comment">% using cross-validation (CV) [4]. This is a data resampling procedure in which models are</span>
0143 <span class="comment">% repeatedly computed, each time on a different subset of the data (called the training set) and</span>
0144 <span class="comment">% compared on another disjoint portion of the data (called the test set) using the defined (i.e.</span>
0145 <span class="comment">% desired) outputs, and some user-selected loss measure. In the default CV, the data is partitioned</span>
0146 <span class="comment">% into 10 blocks, where for each block, a model is computed on the remaining 9 ones and tested</span>
0147 <span class="comment">% against the target values in the current block (called 10-fold blockwise CV). Other variants</span>
0148 <span class="comment">% include k-fold randomized CV, where the data trials are randomly shuffled before a regular</span>
0149 <span class="comment">% blockwise k-fold CV, n times repeated k-fold CV, in which n repeated runs over different</span>
0150 <span class="comment">% shufflings are executed and results averaged, and leave-one-out CV (LOOCV), where a model is</span>
0151 <span class="comment">% computed on all except for one trial, and is then tested on the held-out trial. The loss measure</span>
0152 <span class="comment">% is by default chosen depending on the type of target values in the calibration set and the</span>
0153 <span class="comment">% features of the paradigm so that the user rarely needs to override it (misclassification rate for</span>
0154 <span class="comment">% categorical outputs, mean-square error for continuous outputs, negative log-likelihood for</span>
0155 <span class="comment">% probabilistic regression models, etc.).</span>
0156 <span class="comment">%</span>
0157 <span class="comment">% The loss estimates of bci_train are very convenient and can be used to evaluate a large variety of</span>
0158 <span class="comment">% models on data from a single calibration session. The caveat is that that the estimate</span>
0159 <span class="comment">% systematically fails to cover certain features of actual online situations. First, chaotic</span>
0160 <span class="comment">% dynamics are not captured, as in the other offline case, and second, only a certain fraction of</span>
0161 <span class="comment">% the (time-varying) non-stationarities in the data are captured by the estimate. Most biosignals</span>
0162 <span class="comment">% contain features that vary at certain time scales, from second to second (e.g., dopamine level),</span>
0163 <span class="comment">% minute to minute (e.g., background situation), hour to hour (e.g., tiredness), day to day (e.g.,</span>
0164 <span class="comment">% medication) and year to year (e.g., long-term brain plasticity), all of which can affect the</span>
0165 <span class="comment">% output (quality) of the model. Since calibration sessions are usually short, training/test data is</span>
0166 <span class="comment">% close to each other in time, and the situation typically has little variation (e.g. it may be all</span>
0167 <span class="comment">% offline with no user control involved), the majority of non-stationarities that could degrade the</span>
0168 <span class="comment">% model's performance are not captured, and the estimate is almost surely overly optimistic. How</span>
0169 <span class="comment">% large this effect is depends among others on the stability of the features used by the model, the</span>
0170 <span class="comment">% strength of assumptions imposed by the paradigm, and the variety/coverage of situations present in</span>
0171 <span class="comment">% the calibration data.</span>
0172 <span class="comment">%</span>
0173 <span class="comment">%</span>
0174 <span class="comment">% Paradigm Customization and Structure</span>
0175 <span class="comment">% ====================================</span>
0176 <span class="comment">%</span>
0177 <span class="comment">% In the Approach declaration, a list of name-value pairs can be specified, for example</span>
0178 <span class="comment">% {'CSP', 'Resampling',200, 'SpectralSelection',[7 30], 'EpochExtraction',[-1.5 2.5]}, to override the</span>
0179 <span class="comment">% default values of the chosen paradigm for the given named parameters - practically all paradigms have</span>
0180 <span class="comment">% named parameters (although some community-supplied ones may have position-dependent parameters -</span>
0181 <span class="comment">% like most MATLAB functions). All parameters are basically passed through unmodified to the</span>
0182 <span class="comment">% paradigm in question (usually one of the paradigms/ParadigmXXX classes), so the place to</span>
0183 <span class="comment">% look up what can be specified is the help of the respective class, or by bringing up the GUI config</span>
0184 <span class="comment">% dialog for the given approach (see GUI tutorial).</span>
0185 <span class="comment">%</span>
0186 <span class="comment">% Most paradigms contain similar internal structure, and therefore share common components, which in</span>
0187 <span class="comment">% turn means that most of them share multiple common parameters. It is therefore helpful to know</span>
0188 <span class="comment">% these components. The internal structure of most paradigms contains a sequence of three overall</span>
0189 <span class="comment">% data processing stages. The first stage, Signal Processing, receives (multi-channel) signals, such</span>
0190 <span class="comment">% as EEG, and filters these signals to amplify and focus the information of interest, and to discard</span>
0191 <span class="comment">% the remaining information. The outputs of the first stage are again signals, either continuous or</span>
0192 <span class="comment">% epoched/segmented. The stage may have several successive sub-steps (most of them called filters,</span>
0193 <span class="comment">% some called data set editing operations), such as resampling, frequency filtering, spatial</span>
0194 <span class="comment">% filtering, time window selection, artifact removal, etc.. The toolbox offers a collection of</span>
0195 <span class="comment">% pre-defined filter components (in filters/flt_*) and data set operations (in dataset_ops/set_*),</span>
0196 <span class="comment">% each with their respective default parameters. Most paradigms use at least one or two of these</span>
0197 <span class="comment">% components, usually with custom parameters for them, and the user can override these parameters by</span>
0198 <span class="comment">% specifying the component name (e.g. 'resample' to control the settings of the used sampling rate</span>
0199 <span class="comment">% filter, flt_resample) followed by the parameter value to be passed (e.g. 200 for 200 Hz in the</span>
0200 <span class="comment">% case of flt_resample), or a cell array of parameters if the component accepts multiple parameters,</span>
0201 <span class="comment">% such as flt_ica does. Furthermore, most paradigms not only use a subset of the provided filters,</span>
0202 <span class="comment">% but instead use the entire default Signal Processing pipeline of the toolbox, explained in</span>
0203 <span class="comment">% filters/flt_pipeline. For this reason, all parameters of flt_pipeline can be customized by the</span>
0204 <span class="comment">% user for almost any paradigm (and not just those chosen by the paradigm), i.e. the user can enable</span>
0205 <span class="comment">% and configure stages in the default pipeline which are normally disabled in the given paradigm. Note</span>
0206 <span class="comment">% that flt_pipeline offers a few alias names for some parameters, e.g. 'channels' can be used</span>
0207 <span class="comment">% instead of 'selchans', both controlling filters/flt_selchans; these are listed in flt_pipeline.</span>
0208 <span class="comment">%</span>
0209 <span class="comment">% The second stage of most paradigms is the Feature Extraction stage, which receives the</span>
0210 <span class="comment">% preprocessed signals from the Signal Processing, and extracts certain informative features (e.g.</span>
0211 <span class="comment">% logarithm of the signal power). This stage is usually custom to the paradigm, and is therefore</span>
0212 <span class="comment">% controlled by unique parameters (e.g. 'patterns' in the Common Spatial Patterns [2] paradigm,</span>
0213 <span class="comment">% para_csp).</span>
0214 <span class="comment">%</span>
0215 <span class="comment">% Finally, the feature produced by the Feature Extraction are usually subjected to a last stage, the</span>
0216 <span class="comment">% Machine Learning. In this, a learning component, which is one of the provided</span>
0217 <span class="comment">% machine_learning/ml_train* functions, computes a statistical model of the feature distributions,</span>
0218 <span class="comment">% and their relation to the desired output values. This component is generally selected via the</span>
0219 <span class="comment">% 'learner' parameter, which is exposed by most paradigms. The learner can be specified as name tag,</span>
0220 <span class="comment">% such as 'lda', which refers to ml_trainlda. If the learner component contains parameters which shall</span>
0221 <span class="comment">% be costomized as well, a cell array is passed which contains the name tag followed by the custom</span>
0222 <span class="comment">% parameters, in the order of appearance in the respective learning function. For example,</span>
0223 <span class="comment">% 'learner',{'svmlinear',0.5} selects The linear SVM component and sets its Cost parameter to 0.5,</span>
0224 <span class="comment">% and 'learner',{'logreg',[],'variant','vb-ard'} selects the Logistic Regression component, keeps its</span>
0225 <span class="comment">% first parameter at the default value, and uses the custom variant 'vb-ard', which stands for</span>
0226 <span class="comment">% Variational Bayes with Automatic Relevance Determination (see, e.g., [7]). A small but useful subset</span>
0227 <span class="comment">% of the provided Signal Processing, Feature Extraction and Machine Learning components is compactly</span>
0228 <span class="comment">% described in [5].</span>
0229 <span class="comment">%</span>
0230 <span class="comment">%</span>
0231 <span class="comment">% Customized Example</span>
0232 <span class="comment">% ==================</span>
0233 <span class="comment">%</span>
0234 <span class="comment">% To obtain an online prediction of the working-memory load of a person, a calibration data set in</span>
0235 <span class="comment">% which the person has to maintain varying numbers of items is his/her memory (e.g., using the</span>
0236 <span class="comment">% n-back task, see [6]) can be used as a starting point. In this data set, conditions with one item</span>
0237 <span class="comment">% in memory are marked with the event 'n1', conditions with two items in memory are marked with</span>
0238 <span class="comment">% 'n2', etc. Assuming that working-memory load may be reflected in certain oscillatory processes,</span>
0239 <span class="comment">% though in unknown locations and frequency bands, the paradigm Spec-CSP ([9]) is used as a basis.</span>
0240 <span class="comment">% In its default configuration (see paradigms/ParadigmSpecCSP), it focuses on a relatively narrow</span>
0241 <span class="comment">% frequency band, which shall be relaxed here (in particular, the theta band [10] should be</span>
0242 <span class="comment">% included). Also, by default, the Spec-CSP paradigm selects data epochs at 0.5-3.5 seconds</span>
0243 <span class="comment">% following each (selected) event, which shall be modified to [-2.5 2.5], to get a time coverage</span>
0244 <span class="comment">% that is better adapted to the task. Finally, Spec-CSP by default contains a non-probabilistic</span>
0245 <span class="comment">% classifier (Linear Discriminant Analysis, see machine_learning/ml_trainlda), which we want to</span>
0246 <span class="comment">% change into a largely equivalent, but probabilistic one (Logistic regression, see</span>
0247 <span class="comment">% machine_learning/ml_trainlogreg). Since we assume that the most important part of the spectrum</span>
0248 <span class="comment">% will be the alpha and theta rhythm (peaked at ~10 and ~4Hz), but do not want to completely rule</span>
0249 <span class="comment">% out other frequencies, we additionally impose a prior as a custom in-line (lambda) function of</span>
0250 <span class="comment">% frequency). Since we have more than two classes, but the Spec-CSP is only defined for two classes,</span>
0251 <span class="comment">% the framework automatically applies it to every pair of conditions and uses voting (see</span>
0252 <span class="comment">% machine_learning/ml_trainvote) to arrive at per-class probabilities. Note that this is a major</span>
0253 <span class="comment">% customization.</span>
0254 <span class="comment">%</span>
0255 <span class="comment">%   dataset = io_loadset('data sets/mary/nback.eeg')</span>
0256 <span class="comment">%   myapproach = {'SpecCSP', ...</span>
0257 <span class="comment">%       'SignalProcessing',{'EpochExtraction',[-2.5 2.5], 'FIRFilter',{'Frequencies',[2 4 33 34],'Type','minimum-phase'}}, ...</span>
0258 <span class="comment">%       'Prediction',{'FeatureExtraction',{'SpectralPrior','@(f)1+exp(-(x-10).^2)+exp(-(x-4).^2'}, ...</span>
0259 <span class="comment">%                     'MachineLearning',{'Learner','logreg'}}};</span>
0260 <span class="comment">%   [loss,model,stats] = bci_train('Data',dataset, 'Approach',myapproach, 'TargetMarkers',{'n1','n2','n3'})</span>
0261 <span class="comment">%</span>
0262 <span class="comment">% This model will predict either 1,2, or 3 with high confidence, when the user is maintaining the</span>
0263 <span class="comment">% respective number of items in his/her working memory, but will likely be fairly specific to the</span>
0264 <span class="comment">% task on which it was calibrated.</span>
0265 <span class="comment">%</span>
0266 <span class="comment">%</span>
0267 <span class="comment">% Parameter searching</span>
0268 <span class="comment">% ===================</span>
0269 <span class="comment">%</span>
0270 <span class="comment">% In some cases, the optimal setting of certain parameters of a paradigm might not be known, but may</span>
0271 <span class="comment">% drastically affect the performance of the method. One example are the time boundaries w.r.t. to</span>
0272 <span class="comment">% the supplied events, which may depend on the reaction time of the user, among other things.</span>
0273 <span class="comment">% Another example are regularization parameters which are used to constrain the complexity of the</span>
0274 <span class="comment">% learned model (see, e.g. [11]). Regularization is a very powerful concept which enables methods</span>
0275 <span class="comment">% such as Support Vector Machines and LASSO, in which the parameter is neither designed to be</span>
0276 <span class="comment">% manually selected nor is it very interpretable in terms of brain processes. But most importantly,</span>
0277 <span class="comment">% manual selection of these parameters (by trial and error) invalidates the performance guarantees</span>
0278 <span class="comment">% that are made by the loss estimates: the performance estimate found for the hand-selected model is</span>
0279 <span class="comment">% likely far better than the actual performance of that model. This is because the influence of</span>
0280 <span class="comment">% random fluctuations in the estimate over the possible parameters is maximized by the user when</span>
0281 <span class="comment">% he/she accepts the best one as the actual performance of the method (similar in spirit to the</span>
0282 <span class="comment">% fallacy of multiple hypothesis tests without correction).</span>
0283 <span class="comment">%</span>
0284 <span class="comment">% For these reasons, bci_train offers a generic mechanism to search over parameters (or parameter</span>
0285 <span class="comment">% combinations), in user-defined intervals and granularity, and uses a nested cross-validation</span>
0286 <span class="comment">% method to give unbiased loss estimates. In this method, the search for the best parameter (using</span>
0287 <span class="comment">% cross-validation derived estimates) is done inside an outer cross-validation, in each of its</span>
0288 <span class="comment">% steps, and is restricted to the respective training set of that step. This way, the performance of</span>
0289 <span class="comment">% the search procedure itself can be objectively evaluated on held-out test data. The</span>
0290 <span class="comment">% cross-validation scheme for this inner search procedure can be specified via the OptimizationScheme</span>
0291 <span class="comment">% parameter (part of the Training-Options), which has the same format as the EvaluationScheme</span>
0292 <span class="comment">% parameter. By default, it is set to a 5-fold blockwise cross-validation with 5 trials safety</span>
0293 <span class="comment">% margin. As a downside, parameter search multiplies the time it takes to compute a model by a</span>
0294 <span class="comment">% potentially large factor; the total computation time of bci_train is (# of folds in the outer</span>
0295 <span class="comment">% cross-validation) * (# of folds in the inner cross-validation) * (# of parameter combinations) *</span>
0296 <span class="comment">% (time to compute a single model). Thus, the evaluation (outer) cross-validation may in some cases</span>
0297 <span class="comment">% be turned off ('eval_scheme' set to 0) to obtain a model in a reasonable time, e.g., between a</span>
0298 <span class="comment">% calibration session and a subsequent online session.</span>
0299 <span class="comment">%</span>
0300 <span class="comment">% Any value supplied to the paradigm can be replaced by a search range, written as search(...), to</span>
0301 <span class="comment">% indicate to bci_train that this parameter is subject to a search. The search() clause can be used</span>
0302 <span class="comment">% in any place of the data passed to the paradigm (e.g. inside cell arrays and/or structs), and can</span>
0303 <span class="comment">% run over any data type supported by MATLAB, such as numbers, strings, structs, and vectors.</span>
0304 <span class="comment">%</span>
0305 <span class="comment">%</span>
0306 <span class="comment">% Parameter Search Examples</span>
0307 <span class="comment">% =========================</span>
0308 <span class="comment">%</span>
0309 <span class="comment">% In the case of imagined hand gestures (see first example), the time period in which the user</span>
0310 <span class="comment">% performs the imaginations may not be known in advance (e.g. one user may imagine to clench the</span>
0311 <span class="comment">% fist, while another user may imagine a whole sequence of finger movements). Therefore, the exact</span>
0312 <span class="comment">% boundaries of the relevant data are not known, and can be searched (or spectral heuristics could</span>
0313 <span class="comment">% be used). We assume that the response time of the user following the instruction may vary between</span>
0314 <span class="comment">% 0.25 seconds and 0.75 seconds, and we choose to search over the range at a granualarity of 0.1</span>
0315 <span class="comment">% seconds. The time it takes until the imagination is finished may vary between 1.5 seconds and 4.5</span>
0316 <span class="comment">% seconds, and we search over values at a granularity of 0.5 seconds. Thus, para_csp's default</span>
0317 <span class="comment">% 'epoch' parameter [0.5,3.5] is replaced by [search(0.25:0.1:0.75), search(1.5:0.5:4.5)]:</span>
0318 <span class="comment">%</span>
0319 <span class="comment">%   calib = io_loadset('data sets/john/gestures.eeg')</span>
0320 <span class="comment">%   myapproach = {'CSP' 'SignalProcessing',{'EpochExtraction',[search(0.25:0.1:0.75),search(1.5:0.5:4.5)]}};</span>
0321 <span class="comment">%   [loss,model,stats] = bci_train('Data',calib, 'Approach',myapproach}, 'TargetMarkers',{'left-imag','right-imag'})</span>
0322 <span class="comment">%</span>
0323 <span class="comment">% Since the search runs over 6*7 parameters, and a 5x inner cross-validation is performed, the</span>
0324 <span class="comment">% overall running time will be 6*7*5 = 210x the default running time. If such a procedure shall be</span>
0325 <span class="comment">% run immediately prior to an online session, it is better to disable the outer cross-validation</span>
0326 <span class="comment">% altogether, which brings the time down to 21x of the default.</span>
0327 <span class="comment">%</span>
0328 <span class="comment">%</span>
0329 <span class="comment">% As a second example, suppose that the goal is to predict whether the user perceives some event as</span>
0330 <span class="comment">% being erroneous or not. A possible calibration data set could contain events of two classes, 'err'</span>
0331 <span class="comment">% and 'cor', which encode time points where the user encountered errorneous and correct events. The</span>
0332 <span class="comment">% assumption is that the user's event processing is accompanied by a characteristic slow cortical</span>
0333 <span class="comment">% potential [12] which allows to discern between the two conditions. As a paradigm, we use the</span>
0334 <span class="comment">% ERP version of the Dual-Agumented Lagrange method [13], which makes few assumptions</span>
0335 <span class="comment">% except that the cognitive process of interest is simple enough in its time/space behavior to be</span>
0336 <span class="comment">% tractably recognized. We restrict the analysis to the period of -0.2 to 0.65s around the event,</span>
0337 <span class="comment">% resample to 60Hz, filter to ~0.3-19Hz, and specify a custom parameter search range for the DAL machine</span>
0338 <span class="comment">% learning function. The complexity of the learned model is controlled via a regularization</span>
0339 <span class="comment">% parameter, called Lambda. This parameter is the first user-accessible parameter in the learning</span>
0340 <span class="comment">% function ml_traindal (its first two parameters are implicitly specified by the framework and</span>
0341 <span class="comment">% contain the actual data; this contract holds for all other learning functions</span>
0342 <span class="comment">% machine_learning/ml_train*, as well). Instead of specifying an ad hoc value here, we instead</span>
0343 <span class="comment">% let bci_train search over a large feasible interval.</span>
0344 <span class="comment">%</span>
0345 <span class="comment">%   calib = io_loadset('data sets/john/errorperception.eeg')</span>
0346 <span class="comment">%   myapproach = {'DALERP', ...</span>
0347 <span class="comment">%       'SignalProcessing',{'EpochExtraction',[-0.2 0.65]}, ...</span>
0348 <span class="comment">%       'Prediction',{'MachineLearning',{'Learner',{'dal',search(2.^(8:-0.125:1))}}}};</span>
0349 <span class="comment">%   [loss,model,stats] = bci_train('Data',calib,'Approach',myapproach, 'TargetMarkers',{'err','cor'})</span>
0350 <span class="comment">%</span>
0351 <span class="comment">% This example is for illustrative purposes because the ml_traindal has its own highly optimized</span>
0352 <span class="comment">% parameter search code, which would kick in if the first parameter was specified as an array of</span>
0353 <span class="comment">% possible values (i.e. without the search() clause).</span>
0354 <span class="comment">%</span>
0355 <span class="comment">% Statistics</span>
0356 <span class="comment">% ==========</span>
0357 <span class="comment">%</span>
0358 <span class="comment">% Aside from an average loss measure, a structure of additional statistics can be obtained from</span>
0359 <span class="comment">% bci_train via its third output parameter, Statistics. The most relevant part of the statistics are</span>
0360 <span class="comment">% the per-fold loss measures (computed in each cross-validation fold), which can be used to run</span>
0361 <span class="comment">% statistical tests on the significance of outcomes, etc.; these are in the struct array .per_fold.</span>
0362 <span class="comment">% This also includes the target values (.targ) and predicted values (.pred) for the trials in each</span>
0363 <span class="comment">% fold, as well as the indices of the fold's trials in the full original data set (.indices).</span>
0364 <span class="comment">% Depending on the type of loss measure, additional values may be available per fold (e.g. fraction</span>
0365 <span class="comment">% of true and false positives, etc).</span>
0366 <span class="comment">%</span>
0367 <span class="comment">% If the model was obtained in a parameter search, the field .modelsearch contains the complete set of</span>
0368 <span class="comment">% loss measures and computed models for each tested parameter combination (on the entire calibration</span>
0369 <span class="comment">% set), which includes, among others, the regularization path for regularized classifiers, which</span>
0370 <span class="comment">% allows for very detailed analyses of the computed models.</span>
0371 <span class="comment">%</span>
0372 <span class="comment">% Additional fields include, depending on the type of target variables, .classes and .class_ratio</span>
0373 <span class="comment">% contain the possible output values of the model (e.g. [1,2,3,4,5] in a  standard 5-class</span>
0374 <span class="comment">% classification task) as well as the fraction of data trials belonging to each class. The field</span>
0375 <span class="comment">% .model contains the computed model, the field .expression contains an expression data structure</span>
0376 <span class="comment">% which summarizes the parameters that went into the comptuation of the result(s), including those</span>
0377 <span class="comment">% that determined the data set(s) used for calibration. The function hlp_tostring can format it into</span>
0378 <span class="comment">% a human-readable string.</span>
0379 <span class="comment">%</span>
0380 <span class="comment">%</span>
0381 <span class="comment">% Model Usage</span>
0382 <span class="comment">% ===========</span>
0383 <span class="comment">%</span>
0384 <span class="comment">% The computed model can subsequently be used with other parts of the toolbox. Most importantly, the</span>
0385 <span class="comment">% model can be used with the online system of the toolbox, either via one of the provided online</span>
0386 <span class="comment">% plugins or directly through BCILAB's online application programming interface (API), explained in</span>
0387 <span class="comment">% online_analysis/onl_*. Aside from online analysis, the model can be used for offline analysis of</span>
0388 <span class="comment">% data sets, via the functions bci_predict (make predictions for every trial in a given data set),</span>
0389 <span class="comment">% onl_stream (make predictions for desired time points in a given data set), and bci_preproc</span>
0390 <span class="comment">% (preprocess a given data set into its pre-feature extraction form for analysis and visualization</span>
0391 <span class="comment">% with EEGLAB tools). Finally, model properties can be visualized and inspected using visualization</span>
0392 <span class="comment">% methods (visualizations/vis_*). The model can be saved to disk and re-loaded later.</span>
0393 <span class="comment">%</span>
0394 <span class="comment">%</span>
0395 <span class="comment">% In:</span>
0396 <span class="comment">%    --- core arguments ---</span>
0397 <span class="comment">%</span>
0398 <span class="comment">%    Data : Data set. EEGLAB data set, or stream bundle, or cell array of data sets / stream bundles</span>
0399 <span class="comment">%           to use for calibration/evaluation.</span>
0400 <span class="comment">%</span>
0401 <span class="comment">%    Approach : Computational approach. Specification of a computational approach (usually a cell</span>
0402 <span class="comment">%               array, alternatively a struct). If a cell array, the first cell is the name of the</span>
0403 <span class="comment">%               paradigm (usually just the acronym of an existing ParadigmXXX class), and the rest are</span>
0404 <span class="comment">%               name-value pairs specifying optional custom arguments for the paradigm.</span>
0405 <span class="comment">%</span>
0406 <span class="comment">%   TargetMarkers : Target markers. List of types of those markers around which data shall be used</span>
0407 <span class="comment">%                   for BCI calibration; each marker type encodes a different target class (i.e.</span>
0408 <span class="comment">%                   desired output value) to be learned by the resulting BCI model.</span>
0409 <span class="comment">%</span>
0410 <span class="comment">%                   This can be specified either as a cell array of marker-value pairs, in which</span>
0411 <span class="comment">%                   case each marker type of BCI interest is associated with a particular BCI output</span>
0412 <span class="comment">%                   value (e.g., -1/+1), or as a cell array of marker types (in which case each</span>
0413 <span class="comment">%                   marker will be associated with its respective index as corresponding BCI output</span>
0414 <span class="comment">%                   value, while nested cell arrays are also allowed to group markers that correspond</span>
0415 <span class="comment">%                   to the same output value). See help of set_targetmarkers for further explanation.</span>
0416 <span class="comment">%</span>
0417 <span class="comment">%</span>
0418 <span class="comment">%   --- miscellaneous arguments ---</span>
0419 <span class="comment">%</span>
0420 <span class="comment">%   EventField : Event field to search for target markers, provided as a string. If not provided,</span>
0421 <span class="comment">%                the field 'type' will be used by default.</span>
0422 <span class="comment">%</span>
0423 <span class="comment">%   EvaluationMetric : Evaluation metric. The metric to use in the assessment of model performance</span>
0424 <span class="comment">%                      (via cross-validation). Can be empty, a string, or a function handle.</span>
0425 <span class="comment">%                      See ml_calcloss() for the options (default: [] = auto-select between</span>
0426 <span class="comment">%                      kullback-leibler divergence ('kld'), mean square error ('mse'), mis-classification</span>
0427 <span class="comment">%                      rate ('mcr') and negative log-likelihood ('nll') depending on the type of the</span>
0428 <span class="comment">%                      target and prediction variables, further detailed in ml_calcloss())</span>
0429 <span class="comment">%</span>
0430 <span class="comment">%   EvaluationScheme : Evaluation scheme. Cross-validation scheme to use for evaluation. See</span>
0431 <span class="comment">%                      utl_crossval for the default settings when operating on a single recording</span>
0432 <span class="comment">%                      (there it is called 'scheme'), and utl_collection_partition when operating on</span>
0433 <span class="comment">%                      a collection of data sets. In the case of single data sets, a reasonable</span>
0434 <span class="comment">%                      choice for final results is {'chron',10,5} which stands for 10-fold</span>
0435 <span class="comment">%                      chronological/blockwise cross-validation with 5 trials margin between</span>
0436 <span class="comment">%                      training and test sets. Default: {'chron',5,5}, which is twice as fast, for</span>
0437 <span class="comment">%                      more rapid workflow. A standard choice in machine learning is 10-fold randomized</span>
0438 <span class="comment">%                      cross-validation, which you get by setting this parameter to 10 (though it is</span>
0439 <span class="comment">%                      not ideal for time-series data).</span>
0440 <span class="comment">%</span>
0441 <span class="comment">%   OptimizationScheme : Optimization scheme. Cross-validation scheme to use for parameter search</span>
0442 <span class="comment">%                        (this is a nested cross-validation, only performed if there are parameters</span>
0443 <span class="comment">%                        to search). The format is the same as in EvaluationScheme; default is</span>
0444 <span class="comment">%                        {'chron',5,5}, which is a reasonable choice for final results.</span>
0445 <span class="comment">%</span>
0446 <span class="comment">%   GoalIdentifier : Goal identifier. This is only used for training on multiple recordings and</span>
0447 <span class="comment">%                    serves to identify the data set on which the BCI shall eventually be used</span>
0448 <span class="comment">%                    (e.g., the Subject Id, Day, etc. of the goal data set).</span>
0449 <span class="comment">%</span>
0450 <span class="comment">%   EpochBounds : Epoch bounds override. Tight upper bound of epoch windows used for epoching (by</span>
0451 <span class="comment">%                 default [-5 5]). This is only used if the cross-validation needs to run on</span>
0452 <span class="comment">%                 continuous data because a continuous-data statistic needs to be computed over the</span>
0453 <span class="comment">%                 training set (such as ICA).</span>
0454 <span class="comment">%</span>
0455 <span class="comment">%   CrossvalidationResources : Cross-validation parallelization. Same meaning and options as the</span>
0456 <span class="comment">%                              ParameterSearchEngine parameter, however for the cross-validations.</span>
0457 <span class="comment">%                              By default set to 'global'.</span>
0458 <span class="comment">%</span>
0459 <span class="comment">%   ParameterSearchResources : Parameter search parallelization. If set to 'global', the global BCILAB</span>
0460 <span class="comment">%                              setting will be used to determine when to run this computation. If set</span>
0461 <span class="comment">%                              to 'local', the computation will be done on the local machine.</span>
0462 <span class="comment">%                              Otherwise,the respective scheduler will be used to distribute the</span>
0463 <span class="comment">%                              computation across a cluster (default: 'local')</span>
0464 <span class="comment">%</span>
0465 <span class="comment">%   NestedCrossvalResources : Nested cross-validation parallelization. If set to 'global', the</span>
0466 <span class="comment">%                             global BCILAB setting will be used to determine when to run this</span>
0467 <span class="comment">%                             computation. If set to 'local', the computation will be done on the</span>
0468 <span class="comment">%                             local machine. Otherwise,the respective scheduler will be used to</span>
0469 <span class="comment">%                             distribute the computation across a cluster (default: 'local')</span>
0470 <span class="comment">%</span>
0471 <span class="comment">%   ResourcePool : Parallel compute resouces. If set to ''global'', the globally set BCILAB resource</span>
0472 <span class="comment">%                  pool will be used, otherwise this should be a cell array of 'hostname:port'</span>
0473 <span class="comment">%                  strings (default: 'global')</span>
0474 <span class="comment">%</span>
0475 <span class="comment">% Out:</span>
0476 <span class="comment">%   Loss       : a measure of the overall performance of the paradigm combination, w.r.t. to the</span>
0477 <span class="comment">%                target variable returned by gettarget, computed by the specified loss metric.</span>
0478 <span class="comment">%</span>
0479 <span class="comment">%   Model      : a predictive model (&quot;detector&quot;), as computed by the specified paradigm; can be</span>
0480 <span class="comment">%                loaded into the online system via onl_loaddetector, applied offline to new data via</span>
0481 <span class="comment">%                bci_predict, and analyzed using various visualizers</span>
0482 <span class="comment">%</span>
0483 <span class="comment">%   Statistics : additional statistics, as produced by the specified metric; if the model itself is</span>
0484 <span class="comment">%                determined via parameter search, further statistics from the model searching are in</span>
0485 <span class="comment">%                the subfield stats.model</span>
0486 <span class="comment">%</span>
0487 <span class="comment">% Examples:</span>
0488 <span class="comment">%   % assuming that a data set has been loaded, and a computational approach has been defined</span>
0489 <span class="comment">%   % similarly to the following code:</span>
0490 <span class="comment">%   traindata = io_loadset('bcilab:/userdata/tutorial/imag_movements1/calib/DanielS001R01.dat');</span>
0491 <span class="comment">%   myapproach = {'CSP' 'SignalProcessing',{'EpochExtraction',[0 3.5]}};</span>
0492 <span class="comment">%</span>
0493 <span class="comment">%   % learn a model and get the mis-classification rate, as well as statistics</span>
0494 <span class="comment">%   [trainloss,lastmodel,laststats] = bci_train('Data',traindata,'Approach',myapproach,'TargetMarkers',{'StimulusCode_2','StimulusCode_3'});</span>
0495 <span class="comment">%</span>
0496 <span class="comment">%   % as before, but use a coarser block-wise (chronological) cross-validation (5-fold, with 3 trials margin)</span>
0497 <span class="comment">%   [trainloss,lastmodel,laststats] = bci_train('Data',traindata,'Approach',myapproach,'EvaluationScheme',{'chron',5,3}'TargetMarkers',{'StimulusCode_2','StimulusCode_3'});</span>
0498 <span class="comment">%</span>
0499 <span class="comment">%   % as before, but use a 10-fold randomized cross-validation (rarely recommended)</span>
0500 <span class="comment">%   [trainloss,lastmodel,laststats] = bci_train('Data',traindata,'Approach',myapproach,'EvaluationScheme',10,'TargetMarkers',{'StimulusCode_2','StimulusCode_3'});</span>
0501 <span class="comment">%</span>
0502 <span class="comment">%   % as before, using a 10-fold, 10x repeated randomized cross-validation</span>
0503 <span class="comment">%   [trainloss,lastmodel,laststats] = bci_train('Data',traindata,'Approach',myapproach,'EvaluationScheme',[10 10],'TargetMarkers',{'StimulusCode_2','StimulusCode_3'});</span>
0504 <span class="comment">%</span>
0505 <span class="comment">%   % using a different loss measure (here: mean-square error, instead of the default mis-classification rate)</span>
0506 <span class="comment">%   [trainloss,lastmodel,laststats] = bci_train('Data',traindata,'Approach',myapproach,'EvaluationMetric','mse','TargetMarkers',{'StimulusCode_2','StimulusCode_3'});</span>
0507 <span class="comment">%</span>
0508 <span class="comment">%</span>
0509 <span class="comment">% References:</span>
0510 <span class="comment">%   [1] Pfurtscheller, G., and da Silva, L. &quot;Event-related EEG/MEG synchronization and desynchronization: basic principles.&quot;</span>
0511 <span class="comment">%       Clin Neurophysiol 110, 1842-1857, 1999</span>
0512 <span class="comment">%   [2] Ramoser, H., Mueller-Gerking, J., Pfurtscheller G. &quot;Optimal spatial filtering of single trial EEG during imagined hand movement.&quot;</span>
0513 <span class="comment">%       IEEE Trans Rehabil Eng. Dec 8 (4): 441-6, 2000</span>
0514 <span class="comment">%   [3] MacKay, D. J. C. &quot;Information theory, inference, and learning algorithms.&quot;</span>
0515 <span class="comment">%       Cambridge University Press, 2003.</span>
0516 <span class="comment">%   [4] Duda, R., Hart, P., and Stork, D., &quot;Pattern Classification.&quot;, Second Ed.</span>
0517 <span class="comment">%       John Wiley &amp; Sons, 2001.</span>
0518 <span class="comment">%   [5] Dornhege, G. &quot;Increasing Information Transfer Rates for Brain-Computer Interfacing.&quot;</span>
0519 <span class="comment">%       Ph.D Thesis, University of Potsdam, 2006.</span>
0520 <span class="comment">%   [6] Owen, A. M., McMillan, K. M., Laird, A. R. &amp; Bullmore, E. &quot;N-back working memory paradigm: A meta-analysis of normative functional neuroimaging studies.&quot;</span>
0521 <span class="comment">%       Human Brain Mapping, 25, 46-59, 2005</span>
0522 <span class="comment">%   [7] Bishop, C. M. &quot;Pattern Recognition and Machine Learning.&quot;</span>
0523 <span class="comment">%       Information Science and Statistics. Springer, 2006.</span>
0524 <span class="comment">%   [8] Hastie, T., Tibshirani, R., and Friedman, J. H. &quot;The elements of statistical learning (2nd Ed.).&quot;</span>
0525 <span class="comment">%        Springer, 2009.</span>
0526 <span class="comment">%   [9] Tomioka, R., Dornhege, G., Aihara, K., and Mueller, K.-R.. &quot;An iterative algorithm for spatio-temporal filter optimization.&quot;</span>
0527 <span class="comment">%       In Proceedings of the 3rd International Brain-Computer Interface Workshop and Training Course 2006, pages 22-23. Verlag der Technischen Universitaet Graz, 2006.</span>
0528 <span class="comment">%   [10] Buzsaki, G., &quot;Rhythms of the brain&quot;</span>
0529 <span class="comment">%        Oxford University Press US, 2006</span>
0530 <span class="comment">%   [11] Tibshirani, R. . &quot;Regression Shrinkage and Selection via the Lasso&quot;</span>
0531 <span class="comment">%        Journal of the Royal Statistical Society, Series B (Methodology) 58 (1): 267-288, 1996</span>
0532 <span class="comment">%   [12] Holroyd, C.B., Coles, M.G.. &quot;The neural basis of human error processing: reinforcement learning, dopamine, and the error-related negativity&quot;</span>
0533 <span class="comment">%        Psychological Review, 109, 679-709, 2002</span>
0534 <span class="comment">%   [13] Tomioka, R. and Mueller, K.-R. &quot;A regularized discriminative framework for EEG analysis with application to brain-computer interface&quot;</span>
0535 <span class="comment">%        Neuroimage, 49 (1) pp. 415-432, 2010.</span>
0536 <span class="comment">%   [14] Onton J &amp; Makeig S. &quot;Broadband high-frequency EEG dynamics during emotion imagination.&quot;</span>
0537 <span class="comment">%        Frontiers in Human Neuroscience, 2009.</span>
0538 <span class="comment">%</span>
0539 <span class="comment">% See also:</span>
0540 <span class="comment">%   bci_predict, bci_batchtrain, bci_visualize, bci_annotate, io_loadset,</span>
0541 <span class="comment">%   onl_simulate, onl_newpredictor, utl_crossval, utl_searchmodel,</span>
0542 <span class="comment">%   utl_nested_crossval</span>
0543 <span class="comment">%</span>
0544 <span class="comment">%                               Christian Kothe, Swartz Center for Computational Neuroscience, UCSD</span>
0545 <span class="comment">%                               2010-04-24</span>
0546 
0547 <span class="comment">% handle the legacy cell array syntax by reformatting it to the new one</span>
0548 <span class="keyword">if</span> length(varargin) == 1 &amp;&amp; iscell(varargin{1})    
0549     varargin = varargin{1}; <span class="keyword">end</span>
0550 
0551 <span class="comment">% get the options</span>
0552 opts = arg_define(varargin, <span class="keyword">...</span>
0553     <span class="keyword">...</span><span class="comment"> % core parameters ...</span>
0554     arg_norep({<span class="string">'data'</span>,<span class="string">'Data'</span>},mandatory,[],<span class="string">'Data set. EEGLAB data set, or stream bundle, or cell array of data sets / stream bundles to use for calibration/evaluation.'</span>), <span class="keyword">...</span>
0555     arg({<span class="string">'approach'</span>,<span class="string">'Approach'</span>},[],[],<span class="string">'Computational approach. Specification of a computational approach (usually a cell array, alternatively a struct).'</span>), <span class="keyword">...</span>
0556     arg({<span class="string">'markers'</span>,<span class="string">'TargetMarkers'</span>},{},[],<span class="string">'Target markers. List of types of those markers around which data shall be used for BCI calibration; each marker type encodes a different target class (i.e. desired output value) to be learned by the resulting BCI model. This can be specified either as a cell array of marker-value pairs, in which case each marker type of BCI interest is associated with a particular BCI output value (e.g., -1/+1), or as a cell array of marker types (in which case each marker will be associated with its respective index as corresponding BCI output value, while nested cell arrays are also allowed to group markers that correspond to the same output value). See help of set_targetmarkers for further explanation.'</span>), <span class="keyword">...</span>
0557     arg({<span class="string">'metric'</span>,<span class="string">'EvaluationMetric'</span>,<span class="string">'Metric'</span>,<span class="string">'cvmetric'</span>},<span class="string">'auto'</span>,{<span class="string">'auto'</span>,<span class="string">'mcr'</span>,<span class="string">'mse'</span>,<span class="string">'smse'</span>,<span class="string">'sign'</span>,<span class="string">'nll'</span>,<span class="string">'kld'</span>,<span class="string">'mae'</span>,<span class="string">'max'</span>,<span class="string">'rms'</span>,<span class="string">'bias'</span>,<span class="string">'medse'</span>,<span class="string">'auc'</span>,<span class="string">'cond_entropy'</span>,<span class="string">'cross_entropy'</span>,<span class="string">'f_measure'</span>},<span class="string">'Evaluation metric. The metric to use in the assessment of model performance (via cross-validation); see also ml_calcloss.'</span>), <span class="keyword">...</span>
0558     arg({<span class="string">'eval_scheme'</span>,<span class="string">'EvaluationScheme'</span>},[],[],<span class="string">'Evaluation scheme. Cross-validation scheme to use for evaluation. See utl_crossval for the default settings when operating on a single recording, and utl_collection_partition when operating on a collection of data sets.'</span>), <span class="keyword">...</span>
0559     arg({<span class="string">'opt_scheme'</span>,<span class="string">'OptimizationScheme'</span>},{<span class="string">'chron'</span>,5,5},[],<span class="string">'Optimization scheme. Cross-validation scheme to use for parameter search (this is a nested cross-validation, only performed if there are parameters to search).'</span>), <span class="keyword">...</span>
0560     arg({<span class="string">'field'</span>,<span class="string">'EventField'</span>},<span class="string">'type'</span>,[],<span class="string">'Event field to search for target markers.'</span>), <span class="keyword">...</span>
0561     <span class="keyword">...</span><span class="comment"> % misc parameters ...</span>
0562     arg({<span class="string">'goal_identifier'</span>,<span class="string">'GoalIdentifier'</span>},{},[],<span class="string">'Goal identifier. This is only used for training on multiple recordings and serves to identify the data set on which the BCI shall eventually be used (e.g., Subject Id, Day, etc.).'</span>), <span class="keyword">...</span>
0563     arg({<span class="string">'epoch_bounds'</span>,<span class="string">'EpochBounds'</span>},[],[],<span class="string">'Epoch bounds override. Tight upper bound of epoch windows used for epoching (by default the parameter to set_makepos / EpochExtraction). This is only used if the cross-validation needs to run on continuous data because a continuous-data statistic needs to be computed over the training set (such as ICA).'</span>), <span class="keyword">...</span>
0564     <span class="keyword">...</span><span class="comment"> % parallel computing parameters</span>
0565     arg({<span class="string">'engine_cv'</span>,<span class="string">'CrossvalidationResources'</span>},<span class="string">'global'</span>,{<span class="string">'global'</span>,<span class="string">'local'</span>,<span class="string">'BLS'</span>,<span class="string">'ParallelComputingToolbox'</span>,<span class="string">'Reference'</span>},<span class="string">'Cross-validation parallelization. If set to ''global'', the global BCILAB setting will be used to determine when to run this computation. If set to ''local'', the computation will be done on the local machine. Otherwise,the respective scheduler will be used to distribute the computation across a cluster.'</span>), <span class="keyword">...</span>
0566     arg({<span class="string">'engine_gs'</span>,<span class="string">'GridSearchResources'</span>},<span class="string">'local'</span>,{<span class="string">'global'</span>,<span class="string">'local'</span>,<span class="string">'BLS'</span>,<span class="string">'ParallelComputingToolbox'</span>,<span class="string">'Reference'</span>},<span class="string">'Grid search parallelization. If set to ''global'', the global BCILAB setting will be used to determine when to run this computation. If set to ''local'', the computation will be done on the local machine. Otherwise,the respective scheduler will be used to distribute the computation across a cluster.'</span>), <span class="keyword">...</span>
0567     arg({<span class="string">'engine_ncv'</span>,<span class="string">'NestedCrossvalResources'</span>},<span class="string">'local'</span>,{<span class="string">'global'</span>,<span class="string">'local'</span>,<span class="string">'BLS'</span>,<span class="string">'ParallelComputingToolbox'</span>,<span class="string">'Reference'</span>},<span class="string">'Nested Cross-validation parallelization. If set to ''global'', the global BCILAB setting will be used to determine when to run this computation. If set to ''local'', the computation will be done on the local machine. Otherwise,the respective scheduler will be used to distribute the computation across a cluster.'</span>), <span class="keyword">...</span>
0568     arg({<span class="string">'pool'</span>,<span class="string">'ResourcePool'</span>},<span class="string">'global'</span>,[],<span class="string">'Parallel compute resouces. If set to ''global'', the globally set BCILAB resource pool will be used, otherwise this should be a cell array of hostname:port strings.'</span>), <span class="keyword">...</span>
0569     <span class="keyword">...</span><span class="comment"> % some more misc parameters</span>
0570     arg({<span class="string">'prune_datasets'</span>,<span class="string">'PruneDatasets'</span>},true,[],<span class="string">'Prune datasets from results. If true, any occurrence of a data set in the resulting model or stats struct will be replaced by its symbolic expression or a placeholder string.'</span>), <span class="keyword">...</span>
0571     arg({<span class="string">'prune_nontarget_markers'</span>,<span class="string">'PruneNontargetMarkers'</span>},false,[],<span class="string">'Prune non-target markers. This usually improves the speed of offline processing at the cost of not being able to access misc markers in BCI analysis.'</span>));
0572 
0573 <span class="comment">% if any of the following warnings is ever triggered, the state of data in the caches might have gotten</span>
0574 <span class="comment">% seriously messed up. If disk caching is turned on, it is best to purge the recent cache entries</span>
0575 <span class="comment">% back to when this warning first occurred. note: the toolbox never globally disables these variables;</span>
0576 <span class="comment">% check if a script has turned them off</span>
0577 <span class="keyword">if</span> ~hlp_resolve(<span class="string">'fingerprint_create'</span>,true)
0578     disp(<span class="string">'WARNING: Data fingerprint creation is currently disabled (fingerprint_create set to 0). If you have been modifying your data sets manually in scripts before calling bci_train, it is recommended that you re-start your session, as some of your edits might have gone unnoticed.'</span>); <span class="keyword">end</span>
0579 <span class="keyword">if</span> ~hlp_resolve(<span class="string">'fingerprint_check'</span>,true)
0580     disp(<span class="string">'WARNING: Data fingerprint checking is currently disabled (fingerprint_check set to 0). You can re-enable it by calling exp_set_scoped(@fingerprint_check,1) in the command line.'</span>); <span class="keyword">end</span>
0581 
0582 <span class="comment">% --- pre-process the inputs ---</span>
0583 
0584 <span class="comment">% parse the approach (either it's a paradigm name string, a cell array, or a struct)</span>
0585 <span class="keyword">if</span> ischar(opts.approach)
0586     opts.approach = struct(<span class="string">'paradigm'</span>,opts.approach, <span class="string">'parameters'</span>,{{}});
0587 <span class="keyword">elseif</span> iscell(opts.approach)
0588     opts.approach = struct(<span class="string">'paradigm'</span>,opts.approach{1}, <span class="string">'parameters'</span>,{opts.approach(2:end)}); 
0589 <span class="keyword">elseif</span> ~all(isfield(opts.approach,{<span class="string">'paradigm'</span>,<span class="string">'parameters'</span>}))
0590     error(<span class="string">'The approach must be given either as struct with fields ''paradigm'' and ''parameters'' or as a cell array of the form {paradigmname, param1, param2, param3, ...}'</span>); 
0591 <span class="keyword">end</span>
0592 
0593 
0594 <span class="comment">% parse the paradigm identifier of the approach</span>
0595 paradigm_name = opts.approach.paradigm;
0596 <span class="keyword">if</span> ischar(paradigm_name)
0597     <span class="keyword">if</span> exist([<span class="string">'Paradigm'</span> paradigm_name],<span class="string">'class'</span>)
0598         paradigm_name = [<span class="string">'Paradigm'</span> paradigm_name]; <span class="keyword">end</span>
0599     <span class="keyword">if</span> ~exist(paradigm_name,<span class="string">'class'</span>)
0600         error(<span class="string">'A paradigm class with the name (%s) was not found.'</span>,paradigm_name); <span class="keyword">end</span>
0601 <span class="keyword">elseif</span> isa(paradigm_name,<span class="string">'function_handle'</span>)
0602     info = functions(paradigm_name);
0603     paradigm_name = class(info.workspace{1}.instance);
0604     <span class="keyword">if</span> ~strncmp(paradigm_name,<span class="string">'Paradigm'</span>,8)
0605         error(<span class="string">'The Paradigm argument must be the name of a Paradigm class.'</span>); <span class="keyword">end</span>
0606 <span class="keyword">else</span>
0607     error(<span class="string">'The Paradigm argument must be the name of a class (optionally omitting the &quot;Paradigm&quot; prefix).'</span>);
0608 <span class="keyword">end</span>
0609 instance = eval(paradigm_name); <span class="comment">%#ok&lt;NASGU&gt;</span>
0610 calibrate_func = eval(<span class="string">'@instance.calibrate'</span>);
0611 predict_func = eval(<span class="string">'@instance.predict'</span>);
0612 
0613 
0614 <span class="comment">% parse the parameters of the approach: take the cartesian product over all</span>
0615 <span class="comment">% grid search() expressions in the parameters</span>
0616 paradigm_parameters = hlp_flattensearch(opts.approach.parameters);
0617 <span class="comment">% update the list of filters and machine learners if necessary (to get up-to-date lists of supported modules)</span>
0618 flt_pipeline(<span class="string">'update'</span>);
0619 ml_train(<span class="string">'update'</span>);
0620 <span class="keyword">if</span> ~is_search(paradigm_parameters)
0621     <span class="comment">% use the paradigm function to fill in all defaults (etc) for unspecified arguments</span>
0622     paradigm_parameters = arg_report(<span class="string">'vals'</span>,calibrate_func,paradigm_parameters);
0623 <span class="keyword">else</span>
0624     <span class="comment">% fill in the defaults for each individual search item</span>
0625     <span class="keyword">for</span> k=1:length(paradigm_parameters.parts)
0626         paradigm_parameters.parts{k} = arg_report(<span class="string">'vals'</span>,calibrate_func,paradigm_parameters.parts{k}); <span class="keyword">end</span>
0627 <span class="keyword">end</span>
0628 
0629 <span class="comment">% if the EpochBounds are undefined, see if we can infer them from the data</span>
0630 <span class="keyword">if</span> isempty(opts.epoch_bounds)
0631     bounds = <a href="#_sub2" class="code" title="subfunction res = collect_instances(x,field)">collect_instances</a>(paradigm_parameters,<span class="string">'epobounds'</span>); <span class="comment">% note: direct name reference to set_makepos's parameter</span>
0632     <span class="keyword">if</span> ~isempty(bounds)
0633         bounds = vertcat(bounds{:});
0634         <span class="comment">% we use an upper bound of the encountered bounds if multiple (can be multiple if in a</span>
0635         <span class="comment">% parameter search, or if different bounds are assigned to multiple streams) plus some slack</span>
0636         opts.epoch_bounds = [min(bounds(:,1))-0.1 max(bounds(:,2))+0.1];
0637     <span class="keyword">end</span>
0638 <span class="keyword">end</span>
0639 
0640 paradigm_parameters = {paradigm_parameters};
0641 
0642 
0643 
0644 <span class="comment">% --- set up common arguments to the cross-validation &amp; model search ---</span>
0645 
0646 <span class="comment">% turn data into a trivial collection, if necessary</span>
0647 <span class="keyword">if</span> isstruct(opts.data)
0648     opts.data = {opts.data}; <span class="keyword">end</span>
0649 
0650 <span class="comment">% do some pre-processing and uniformization of the data</span>
0651 <span class="keyword">for</span> k=1:length(opts.data)
0652     <span class="comment">% turn each data set into a stream bundle, if necessary</span>
0653     <span class="keyword">if</span> ~isfield(opts.data{k},<span class="string">'streams'</span>)
0654         opts.data{k} = struct(<span class="string">'streams'</span>,{opts.data(k)}); <span class="keyword">end</span>
0655     <span class="comment">% annotate target markers in 1st stream according to the specified event types</span>
0656     <span class="keyword">if</span> ~isempty(opts.markers)
0657         <span class="keyword">if</span> isempty(opts.epoch_bounds)
0658             disp(<span class="string">'Note: TargetMarkers were specified, but epoch bounds could not be deduced from the data (likely processing is not using epoch extraction). Assuming some default bounds [-0.5 0.5].'</span>); 
0659             opts.epoch_bounds = [-0.5 0.5];
0660         <span class="keyword">end</span>
0661         <span class="comment">% (there are 3 possible TargetMarker formats to handle)</span>
0662         <span class="keyword">if</span> length(opts.markers) == 1 &amp;&amp; ischar(opts.markers{1}) &amp;&amp; strcmp(opts.markers{1}, <span class="string">'actualvalues'</span>)
0663             opts.data{k}.streams{1} = set_targetmarkers(<span class="string">'Signal'</span>,opts.data{k}.streams{1},<span class="string">'EventMap'</span>,opts.markers,<span class="string">'EpochBounds'</span>,opts.epoch_bounds, <span class="string">'EventField'</span>, opts.field, <span class="string">'PruneNontarget'</span>,opts.prune_nontarget_markers);
0664         <span class="keyword">elseif</span> all(cellfun(<span class="string">'isclass'</span>,opts.markers,<span class="string">'char'</span>) | cellfun(<span class="string">'isclass'</span>,opts.markers,<span class="string">'cell'</span>))
0665             opts.data{k}.streams{1} = set_targetmarkers(<span class="string">'Signal'</span>,opts.data{k}.streams{1},<span class="string">'EventTypes'</span>,opts.markers,<span class="string">'EpochBounds'</span>,opts.epoch_bounds, <span class="string">'EventField'</span>, opts.field, <span class="string">'PruneNontarget'</span>,opts.prune_nontarget_markers);
0666         <span class="keyword">else</span>
0667             opts.data{k}.streams{1} = set_targetmarkers(<span class="string">'Signal'</span>,opts.data{k}.streams{1},<span class="string">'EventMap'</span>,opts.markers,<span class="string">'EpochBounds'</span>,opts.epoch_bounds, <span class="string">'EventField'</span>, opts.field, <span class="string">'PruneNontarget'</span>,opts.prune_nontarget_markers);
0668         <span class="keyword">end</span>
0669     <span class="keyword">end</span>    
0670     <span class="comment">% check the bundle for consistency: in particular, whether the data matches the .tracking field</span>
0671     opts.data{k} = utl_check_bundle(opts.data{k});
0672 <span class="keyword">end</span>
0673 <span class="comment">% ... and store some tracking information for the resulting model</span>
0674 source_data = opts.data;
0675 <span class="keyword">for</span> k=1:length(source_data)
0676     source_data{k}.streams = cellfun(@utl_purify_expression,source_data{k}.streams,<span class="string">'UniformOutput'</span>,false); <span class="keyword">end</span>
0677 
0678 <span class="comment">% determine whether we have to send our data over the network</span>
0679 nonlocal = false;
0680 <span class="keyword">for</span> computescope = {<span class="string">'engine_cv'</span>,<span class="string">'engine_gs'</span>,<span class="string">'engine_ncv'</span>}
0681     <span class="keyword">if</span> strcmp(opts.(computescope{1}),<span class="string">'global'</span>)
0682         nonlocal = nonlocal || ~strcmp(par_globalengine,<span class="string">'local'</span>); 
0683     <span class="keyword">else</span> 
0684         nonlocal = nonlocal || ~strcmp(opts.(computescope{1}),<span class="string">'local'</span>);
0685     <span class="keyword">end</span>
0686 <span class="keyword">end</span>
0687 
0688 <span class="keyword">if</span> nonlocal
0689     <span class="comment">% if we're running non-locally, transfer only a minimal amount of data (i.e. just the expressions) over the network</span>
0690     opts.data = source_data;
0691     <span class="comment">% ... and make sure that these expressions get properly cached on the server side...</span>
0692     <span class="keyword">for</span> k=1:length(opts.data)
0693         opts.data{k}.streams = cellfun(@(x)exp_block({exp_rule(@memoize,{<span class="string">'memory'</span>,1})},x),opts.data{k}.streams,<span class="string">'UniformOutput'</span>,false); <span class="keyword">end</span>
0694 <span class="keyword">end</span>
0695 
0696 
0697 <span class="keyword">if</span> isscalar(opts.data)    
0698     <span class="comment">% got a single recording: cross-validate within it</span>
0699     opts.data = opts.data{1};
0700     <span class="keyword">if</span> isempty(opts.eval_scheme)
0701         opts.eval_scheme = {<span class="string">'chron'</span>,5,5}; <span class="keyword">end</span>
0702     <span class="comment">% set up the utl_crossval (et al.) arguments for a within-set cross-validation</span>
0703     crossval_args = { <span class="keyword">...</span>
0704         <span class="string">'trainer'</span>, @(trainset,varargin) utl_complete_model(calibrate_func(<span class="string">'collection'</span>,{trainset},varargin{:}),predict_func), <span class="keyword">...</span>
0705         <span class="string">'tester'</span>, @(testset,model) predict_func(utl_preprocess_bundle(testset,model),model), <span class="keyword">...</span>
0706         <span class="string">'partitioner'</span>, @(dataset,inds) utl_partition_bundle(dataset,inds,opts.epoch_bounds), <span class="keyword">...</span>
0707         <span class="string">'target'</span>, @(dataset) set_gettarget(dataset.streams{1}), <span class="keyword">...</span>
0708         <span class="string">'argform'</span>,<span class="string">'clauses'</span>, <span class="keyword">...</span>
0709         <span class="string">'args'</span>,paradigm_parameters};
0710 <span class="keyword">else</span>
0711     <span class="comment">% got a data set collection: cross-validate across them</span>
0712     <span class="keyword">if</span> isempty(opts.eval_scheme)
0713         opts.eval_scheme = {}; <span class="keyword">end</span>
0714     <span class="comment">% set up the utl_crossval (et al.) arguments for a cross-validation on data sets</span>
0715     crossval_args = { <span class="keyword">...</span>
0716         <span class="string">'trainer'</span>, @(traincollection,varargin) utl_complete_model(calibrate_func(<span class="string">'collection'</span>,traincollection,varargin{:}),predict_func), <span class="keyword">...</span>
0717         <span class="string">'tester'</span>, @(testcollection,model) utl_collection_tester(testcollection,model,predict_func), <span class="keyword">...</span>
0718         <span class="string">'partitioner'</span>, @(fullcollection,inds) utl_collection_partition(fullcollection,inds,opts.eval_scheme), <span class="keyword">...</span>
0719         <span class="string">'target'</span>, @utl_collection_targets, <span class="keyword">...</span>
0720         <span class="string">'argform'</span>,<span class="string">'clauses'</span>, <span class="keyword">...</span>
0721         <span class="string">'args'</span>,[paradigm_parameters {<span class="string">'goal_identifier'</span>,opts.goal_identifier}]};
0722 <span class="keyword">end</span>
0723 
0724 <span class="comment">% pre-pend some user arguments of bci_train (e.g., pool, policy, ...) to the control arguments (to be overridden by what is defined in crossval_args)</span>
0725 crossval_args = [{rmfield(opts,{<span class="string">'data'</span>,<span class="string">'approach'</span>,<span class="string">'markers'</span>,<span class="string">'goal_identifier'</span>,<span class="string">'epoch_bounds'</span>})} crossval_args];
0726 
0727 <span class="comment">% note: the following line is a fancy way of calling [measure,model,stats] = run_computation(opts,crossval_args);</span>
0728 <span class="comment">% what is different is that the variables fingerprint_check and fingerprint_create will be set to 0</span>
0729 <span class="comment">% for the scope of that computation (effectively disabling some unnecessary checks for performance)</span>
0730 [measure,model,stats] = hlp_scope({<span class="string">'fingerprint_check'</span>,0,<span class="string">'fingerprint_create'</span>,0},@<a href="#_sub1" class="code" title="subfunction [measure,model,stats] = run_computation(opts,crossval_args)">run_computation</a>,opts,crossval_args);
0731 
0732 <span class="comment">% annotate the result with additional info</span>
0733 stats.is_result = true;
0734 stats.timestamp = now;
0735 model.paradigm = paradigm_name;
0736 model.options = paradigm_parameters;
0737 model.source_data = source_data;
0738 model.control_options = rmfield(opts,<span class="string">'data'</span>);
0739 model.epoch_bounds = opts.epoch_bounds;
0740 <span class="comment">% remove some additional data overhead from model &amp; stats to keep them small</span>
0741 <span class="keyword">if</span> opts.prune_datasets
0742     model = utl_prune_datasets(model);
0743     stats = utl_prune_datasets(stats);
0744 <span class="keyword">end</span>
0745 model = utl_prune_handles(model);
0746 stats = utl_prune_handles(stats);
0747 model.tracking.prediction_function = paradigm_name;
0748 stats.model = model;
0749 
0750 
0751 
0752 <span class="comment">% run the actual computation of bci_train (model search/training, (nested) cross-validation)</span>
0753 <a name="_sub1" href="#_subfunctions" class="code">function [measure,model,stats] = run_computation(opts,crossval_args)</a>
0754 t0 = tic;
0755 <span class="comment">% issue model search</span>
0756 job = par_beginschedule({{@hlp_getresult,{1:2}, @utl_searchmodel, opts.data, crossval_args{:}, <span class="string">'scheme'</span>,opts.opt_scheme}}, opts, <span class="string">'engine'</span>,opts.engine_cv, <span class="string">'keep'</span>,false);
0757 <span class="comment">% estimate the model performance, if requested (0-fold cross-validation = cross-validation turned off)</span>
0758 <span class="keyword">if</span> ~isequal(opts.eval_scheme,0)
0759     [measure,stats] = utl_nested_crossval(opts.data, crossval_args{:});
0760 <span class="keyword">else</span>
0761     measure = NaN;
0762 <span class="keyword">end</span>
0763 <span class="comment">% collect &amp; aggregate results</span>
0764 results = par_endschedule(job, <span class="string">'keep'</span>,false);
0765 [model,stats.modelsearch] = deal(results{1}{:});
0766 model.tracking.computation_time = toc(t0);
0767 
0768 
0769 <span class="comment">% collect all instances of values of the given field in a data structure</span>
0770 <a name="_sub2" href="#_subfunctions" class="code">function res = collect_instances(x,field)</a>
0771 res = {};
0772 <span class="keyword">if</span> isstruct(x)
0773     <span class="keyword">for</span> fn=fieldnames(x)'
0774         fname = fn{1};
0775         <span class="keyword">if</span> strcmp(fname,field)
0776             <span class="comment">% this is our field: aggregate all instances as a cell array</span>
0777             tmp = {x.(fname)};
0778         <span class="keyword">else</span>
0779             tmp = <a href="#_sub2" class="code" title="subfunction res = collect_instances(x,field)">collect_instances</a>({x.(fname)},field);
0780         <span class="keyword">end</span>
0781         <span class="keyword">if</span> ~isempty(tmp)
0782             res = [res tmp(:)]; <span class="keyword">end</span>
0783     <span class="keyword">end</span>
0784 <span class="keyword">elseif</span> iscell(x)
0785     <span class="keyword">for</span> c=1:numel(x)
0786         res = [res <a href="#_sub2" class="code" title="subfunction res = collect_instances(x,field)">collect_instances</a>(x{c},field)]; <span class="keyword">end</span>
0787 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Tue 20-Aug-2013 03:44:10 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>